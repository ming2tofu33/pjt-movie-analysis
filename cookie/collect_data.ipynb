{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021378ff",
   "metadata": {},
   "source": [
    "# ë°ì´í„° ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0a6dd",
   "metadata": {},
   "source": [
    "## 2005ë…„ë„ ë¶€í„° 2019ë…„ë„ í•œêµ­ ì œì‘ ì˜í™” ë°ì´í„° ìˆ˜ì§‘\n",
    "- 2005-01-01 ~ 2019-12-31 (ì½”ë¡œë‚˜19 ì´ì „)\n",
    "- KOBIS(=KOFIC OpenAPI)ì—ì„œ 'ì£¼ê°„ ë°•ìŠ¤ì˜¤í”¼ìŠ¤ Top10ì— í•œ ë²ˆì´ë¼ë„ ë“±ì¥'í•œ ì˜í™”ë§Œ ì„ ë³„.\n",
    "- í•œêµ­ ì œì‘ë§Œ í•„í„°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "2005-01-01 ~ 2019-12-31\n",
    "KOBIS(=KOFIC OpenAPI)ì—ì„œ 'ì£¼ê°„ ë°•ìŠ¤ì˜¤í”¼ìŠ¤ Top10ì— í•œ ë²ˆì´ë¼ë„ ë“±ì¥'í•œ ì˜í™”ë§Œ ì„ ë³„\n",
    "â†’ í•œêµ­ ì œì‘ë§Œ í•„í„° â†’ TMDB ìŠ¤íƒ€ì¼ ìŠ¤í‚¤ë§ˆ CSV ìƒì„±\n",
    "(revenue = êµ­ë‚´ ìµœì¢… ëˆ„ì ë§¤ì¶œ, audience_total = êµ­ë‚´ ìµœì¢… ëˆ„ì ê´€ê°)\n",
    "\n",
    "ì¶œë ¥ ì—´ ìˆœì„œ:\n",
    "movie_id,title,original_title,original_language,release_date,runtime,budget,\n",
    "revenue,vote_average,vote_count,popularity,genres,production_companies,\n",
    "production_countries,release_year,release_month,audience_total\n",
    "\"\"\"\n",
    "\n",
    "import os, time, json, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime, timedelta\n",
    "from urllib.parse import urlencode\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ========= ê¸°ê°„/ê²½ë¡œ ì„¤ì • =========\n",
    "START = date(2005, 1, 1)\n",
    "END   = date(2019,12,31)\n",
    "\n",
    "OUT_DIR       = \"./data/raw\"\n",
    "WEEKLY_PICKLE = f\"{OUT_DIR}/kobis_weekly_pool.pkl\"      # ì£¼ê°„ ìŠ¤ìº” ê²°ê³¼ ìºì‹œ\n",
    "OUT_PARTIAL   = f\"{OUT_DIR}/kobis_weekly_partial.csv\"   # ë©”íƒ€ ëˆ„ì (ì¬ì‹œì‘ìš©)\n",
    "OUT_FINAL     = f\"{OUT_DIR}/kobis_weekly_raw.csv\"     # ìµœì¢… TMDBí˜•\n",
    "\n",
    "# í•˜ë£¨ì— ì²˜ë¦¬í•  movieInfo ê°œìˆ˜(ì¿¼í„° ë”°ë¼ ì¡°ì •)\n",
    "MOVIES_PER_RUN = 1000\n",
    "\n",
    "# ìš”ì²­/ì¬ì‹œë„\n",
    "TIMEOUT = 20\n",
    "RETRY   = 3\n",
    "SLEEP   = 0.12\n",
    "\n",
    "# ========= ì¸ì¦ =========\n",
    "load_dotenv()\n",
    "KOBIS_KEY = os.getenv(\"KOFIC_API_KEY\") or os.getenv(\"KOBIS_KEY\")\n",
    "BASE = \"https://www.kobis.or.kr/kobisopenapi/webservice/rest\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ========= ê³µí†µ HTTP =========\n",
    "def kobis_get(path, params, retry=RETRY):\n",
    "    q = {\"key\": KOBIS_KEY, **params}\n",
    "    url = f\"{BASE}{path}.json?{urlencode(q)}\"\n",
    "    last = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=TIMEOUT)\n",
    "            if r.status_code in (429,500,502,503,504):\n",
    "                time.sleep(min(2**i,8)); continue\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if data.get(\"faultInfo\"):\n",
    "                fi = data[\"faultInfo\"]\n",
    "                raise RuntimeError(f\"KOBIS fault: {fi.get('message')} (code={fi.get('errorCode')})\\nURL: {url}\")\n",
    "            time.sleep(SLEEP)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            if i == retry-1: raise\n",
    "            time.sleep(min(2**i,8))\n",
    "    raise RuntimeError(last)\n",
    "\n",
    "# ========= ìœ í‹¸ =========\n",
    "def sundays(start: date, end: date):\n",
    "    # start ê¸°ì¤€ ê·¸ ì£¼ ì¼ìš”ì¼(weekGb=0 ì‚¬ìš©)\n",
    "    s = start + timedelta(days=(6 - start.weekday()))\n",
    "    while s <= end:\n",
    "        yield s\n",
    "        s += timedelta(days=7)\n",
    "\n",
    "def to_iso_from_yyyymmdd(s):\n",
    "    if not s: return pd.NA\n",
    "    s = str(s)\n",
    "    return f\"{s[:4]}-{s[4:6]}-{s[6:]}\" if len(s) >= 8 else pd.NA\n",
    "\n",
    "def json_list_str(xs):\n",
    "    if xs is None: return \"[]\"\n",
    "    if isinstance(xs, list): return json.dumps(xs, ensure_ascii=False)\n",
    "    return json.dumps([str(xs)], ensure_ascii=False)\n",
    "\n",
    "# ========= 1) ì£¼ê°„ Top10 ìŠ¤ìº”: ë“±ì¥ ì˜í™” + ìµœì¢… ëˆ„ì  =========\n",
    "def weekly_scan():\n",
    "    \"\"\"\n",
    "    ì£¼ê°„ ë°•ìŠ¤ì˜¤í”¼ìŠ¤(Top10) ì „ì²´ ì£¼ì°¨ ìŠ¤ìº” â†’ movieCdë³„ ìµœëŒ“ê°’ ëˆ„ì ë§¤ì¶œ/ê´€ê° ë° ê¸°ë³¸ ì •ë³´ ëª¨ìŒ\n",
    "    ë°˜í™˜: dict[movieCd] = {max_sales, max_audi, movieNm, openDt, weeks}\n",
    "    \"\"\"\n",
    "    pool = {}  # movieCd -> dict\n",
    "    for s in tqdm(list(sundays(START, END)), desc=\"Weekly scan (Top10)\"):\n",
    "        js = kobis_get(\"/boxoffice/searchWeeklyBoxOfficeList\",\n",
    "                       {\"targetDt\": s.strftime(\"%Y%m%d\"), \"weekGb\": \"0\"})\n",
    "        items = js.get(\"boxOfficeResult\",{}).get(\"weeklyBoxOfficeList\",[]) or []\n",
    "        for it in items:\n",
    "            cd  = it.get(\"movieCd\")\n",
    "            if not cd: continue\n",
    "            nm  = it.get(\"movieNm\")\n",
    "            odt = it.get(\"openDt\")  # yyyymmdd\n",
    "            salesAcc = pd.to_numeric(it.get(\"salesAcc\"), errors=\"coerce\") or 0\n",
    "            audiAcc  = pd.to_numeric(it.get(\"audiAcc\"),  errors=\"coerce\") or 0\n",
    "            rec = pool.get(cd, {\"max_sales\":0, \"max_audi\":0, \"movieNm\":nm, \"openDt\":odt, \"weeks\":0})\n",
    "            rec[\"max_sales\"] = max(rec[\"max_sales\"], salesAcc)\n",
    "            rec[\"max_audi\"]  = max(rec[\"max_audi\"],  audiAcc)\n",
    "            rec[\"weeks\"]     = rec[\"weeks\"] + 1\n",
    "            if not rec.get(\"movieNm\"):  rec[\"movieNm\"] = nm\n",
    "            if not rec.get(\"openDt\"):   rec[\"openDt\"]  = odt\n",
    "            pool[cd] = rec\n",
    "    pd.to_pickle(pool, WEEKLY_PICKLE)\n",
    "    return pool\n",
    "\n",
    "# ========= 2) movieInfo ë©”íƒ€(í•œêµ­ ì œì‘ í•„í„°) + TMDB ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜ =========\n",
    "def fetch_movie_info(cd: str):\n",
    "    js = kobis_get(\"/movie/searchMovieInfo\", {\"movieCd\": cd})\n",
    "    return js.get(\"movieInfoResult\",{}).get(\"movieInfo\",{}) or {}\n",
    "\n",
    "def is_korean_production(info) -> bool:\n",
    "    nations = [n.get(\"nationNm\") for n in (info.get(\"nations\") or []) if n.get(\"nationNm\")]\n",
    "    return any(str(n).strip() in {\"í•œêµ­\",\"ëŒ€í•œë¯¼êµ­\",\"Korea\",\"South Korea\",\"Republic of Korea\"} for n in nations)\n",
    "\n",
    "def to_tmdb_row(cd, pool_rec, info):\n",
    "    movieNm   = info.get(\"movieNm\") or pool_rec.get(\"movieNm\")\n",
    "    movieNmEn = info.get(\"movieNmEn\") or movieNm\n",
    "    openDt    = info.get(\"openDt\") or pool_rec.get(\"openDt\")\n",
    "    iso       = to_iso_from_yyyymmdd(openDt)\n",
    "    dt        = pd.to_datetime(iso, errors=\"coerce\") if pd.notna(iso) else pd.NaT\n",
    "\n",
    "    showTm    = pd.to_numeric(info.get(\"showTm\"), errors=\"coerce\")\n",
    "    genres    = [g.get(\"genreNm\")   for g in (info.get(\"genres\")   or []) if g.get(\"genreNm\")]\n",
    "    companies = [c.get(\"companyNm\") for c in (info.get(\"companys\") or []) if c.get(\"companyNm\")]\n",
    "\n",
    "    return {\n",
    "        \"movie_id\": cd,\n",
    "        \"title\": movieNm,\n",
    "        \"original_title\": movieNmEn,\n",
    "        \"original_language\": \"ko\",\n",
    "        \"release_date\": iso,\n",
    "        \"runtime\": showTm,\n",
    "        \"budget\": pd.NA,\n",
    "        \"revenue\": float(pool_rec[\"max_sales\"]),       # êµ­ë‚´ ìµœì¢… ëˆ„ì ë§¤ì¶œ(ì›)\n",
    "        \"vote_average\": pd.NA,\n",
    "        \"vote_count\": pd.NA,\n",
    "        \"popularity\": pd.NA,\n",
    "        \"genres\": json_list_str(genres),\n",
    "        \"production_companies\": json_list_str(companies),\n",
    "        \"production_countries\": json_list_str([\"KR\"]),\n",
    "        \"release_year\": (dt.year  if pd.notna(dt) else pd.NA),\n",
    "        \"release_month\": (dt.month if pd.notna(dt) else pd.NA),\n",
    "        \"audience_total\": float(pool_rec[\"max_audi\"]), # êµ­ë‚´ ìµœì¢… ëˆ„ì ê´€ê°\n",
    "    }\n",
    "\n",
    "# ========= 3) ì‹¤í–‰(ì¬ì‹œì‘ ê°€ëŠ¥) =========\n",
    "def main():\n",
    "    if not KOBIS_KEY:\n",
    "        raise SystemExit(\"âŒ .envì— KOFIC_API_KEY(=KOBIS_KEY)ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 1) ì£¼ê°„ ìŠ¤ìº”(ìºì‹œ í™œìš©)\n",
    "    if os.path.exists(WEEKLY_PICKLE):\n",
    "        pool = pd.read_pickle(WEEKLY_PICKLE)\n",
    "    else:\n",
    "        pool = weekly_scan()\n",
    "\n",
    "    # ì£¼ê°„ì— í•œ ë²ˆì´ë¼ë„ ì¡íŒ ì˜í™”ë§Œ(=ëˆ„ì ë§¤ì¶œ ì¶”ì  ê°€ëŠ¥)\n",
    "    candidates = [cd for cd, rec in pool.items() if rec.get(\"max_sales\",0) > 0]\n",
    "\n",
    "    # 2) ì´ë¯¸ ìˆ˜ì§‘í•œ partial ì½ê¸°(ì¬ì‹œì‘)\n",
    "    done = set()\n",
    "    if os.path.exists(OUT_PARTIAL):\n",
    "        prev = pd.read_csv(OUT_PARTIAL, dtype=str)\n",
    "        if \"movie_id\" in prev.columns:\n",
    "            done = set(prev[\"movie_id\"].astype(str).tolist())\n",
    "\n",
    "    todo = [cd for cd in candidates if cd not in done]\n",
    "    if not todo:\n",
    "        print(\"âœ… ëª¨ë‘ ì²˜ë¦¬ë¨. ìµœì¢… íŒŒì¼ë§Œ ì •ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        batch = todo[:MOVIES_PER_RUN]\n",
    "        print(f\"ì´ë²ˆ ë°°ì¹˜: {len(batch)}í¸ / ë‚¨ì€ {len(todo)-len(batch)}í¸\")\n",
    "\n",
    "        rows = []\n",
    "        for cd in tqdm(batch, desc=\"movieInfo + merge (KR only)\"):\n",
    "            try:\n",
    "                info = fetch_movie_info(cd)\n",
    "                # í•œêµ­ ì œì‘ í•„í„° + ê°œë´‰ì¼(ê¸°ê°„ ë‚´ ì•ˆì „ë§)\n",
    "                if not is_korean_production(info):\n",
    "                    continue\n",
    "                odt = info.get(\"openDt\") or pool[cd].get(\"openDt\")\n",
    "                if not odt or len(str(odt)) != 8:\n",
    "                    continue\n",
    "                # ê¸°ê°„ ì•ˆì „ë§ (ì—´ë¦° ë‚ ì§œ ê¸°ì¤€)\n",
    "                y, m, d = int(odt[:4]), int(odt[4:6]), int(odt[6:8])\n",
    "                opened = date(y,m,d)\n",
    "                if opened < START or opened > END:\n",
    "                    continue\n",
    "\n",
    "                row = to_tmdb_row(cd, pool[cd], info)\n",
    "                rows.append(row)\n",
    "            except Exception as e:\n",
    "                print(\"skip\", cd, e)\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows)\n",
    "            header = not os.path.exists(OUT_PARTIAL)\n",
    "            df.to_csv(OUT_PARTIAL, index=False, mode=(\"w\" if header else \"a\"),\n",
    "                      header=header, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 3) ìµœì¢… ì •ë¦¬/ì €ì¥(TMDB ìŠ¤í‚¤ë§ˆ)\n",
    "    cols = [\"movie_id\",\"title\",\"original_title\",\"original_language\",\"release_date\",\"runtime\",\"budget\",\n",
    "            \"revenue\",\"vote_average\",\"vote_count\",\"popularity\",\"genres\",\"production_companies\",\n",
    "            \"production_countries\",\"release_year\",\"release_month\",\"audience_total\"]\n",
    "\n",
    "    part = pd.read_csv(OUT_PARTIAL, dtype=str) if os.path.exists(OUT_PARTIAL) else pd.DataFrame(columns=cols)\n",
    "    if not part.empty:\n",
    "        part[\"release_year\"]   = pd.to_numeric(part[\"release_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        part[\"release_month\"]  = pd.to_numeric(part[\"release_month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        part[\"runtime\"]        = pd.to_numeric(part[\"runtime\"], errors=\"coerce\")\n",
    "        part[\"revenue\"]        = pd.to_numeric(part[\"revenue\"], errors=\"coerce\")\n",
    "        part[\"audience_total\"] = pd.to_numeric(part[\"audience_total\"], errors=\"coerce\")\n",
    "        part = part.drop_duplicates(subset=[\"movie_id\"]).sort_values([\"release_year\",\"release_month\",\"title\"])\n",
    "\n",
    "    part.reindex(columns=cols).to_csv(OUT_FINAL, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… ì €ì¥: {OUT_FINAL} (rows={len(part):,})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b0ce9",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "- \"budget\", \"vote_average\", \"vote_count\", \"popularity\" ì€ ì—†ìœ¼ë¯€ë¡œ ì˜ˆì™¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272042c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ shape: (927, 17)\n",
      "\n",
      "ì •ë¦¬ í›„ shape: (927, 17)\n",
      "\n",
      "ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ë³€í™”:\n",
      "                      na_before  na_after  delta\n",
      "audience_total                0         0      0\n",
      "budget                      927       927      0\n",
      "genres                        0         0      0\n",
      "movie_id                      0         0      0\n",
      "original_language             0         0      0\n",
      "original_title                0         0      0\n",
      "popularity                  927       927      0\n",
      "production_companies          0         0      0\n",
      "production_countries          0         0      0\n",
      "release_date                  0         0      0\n",
      "release_month                 0         0      0\n",
      "release_year                  0         0      0\n",
      "revenue                       0         0      0\n",
      "runtime                       0         0      0\n",
      "title                         0         0      0\n",
      "vote_average                927       927      0\n",
      "vote_count                  927       927      0\n",
      "\n",
      "ì €ì¥ ì™„ë£Œ â†’ ./data/raw/kobis_weekly_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# kobis_weekly_clean.ipynb\n",
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "PATH_IN  = \"./data/raw/kobis_weekly_raw.csv\"\n",
    "PATH_OUT = \"./data/raw/kobis_weekly_clean.csv\"\n",
    "\n",
    "df = pd.read_csv(PATH_IN, dtype={\"movie_id\": str})\n",
    "print(\"ì›ë³¸ shape:\", df.shape)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í˜„í™©(ì „)\n",
    "na_before = df.isna().sum().rename(\"na_before\")\n",
    "\n",
    "# ìŠ¤í‚¤ë§ˆ ë³´ê°•\n",
    "for col in [\"budget\", \"vote_average\", \"vote_count\", \"popularity\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "\n",
    "# í˜• ë³€í™˜\n",
    "num_cols = [\"runtime\", \"revenue\", \"audience_total\", \"vote_average\", \"vote_count\", \"popularity\"]\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "if \"release_date\" in df.columns:\n",
    "    df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
    "\n",
    "# ì—°/ì›” ì±„ì›€\n",
    "if \"release_year\" not in df.columns:  df[\"release_year\"]  = pd.NA\n",
    "if \"release_month\" not in df.columns: df[\"release_month\"] = pd.NA\n",
    "\n",
    "mask_dt = df[\"release_date\"].notna()\n",
    "df.loc[df[\"release_year\"].isna()  & mask_dt, \"release_year\"]  = df.loc[mask_dt, \"release_date\"].dt.year\n",
    "df.loc[df[\"release_month\"].isna() & mask_dt, \"release_month\"] = df.loc[mask_dt, \"release_date\"].dt.month\n",
    "\n",
    "df[\"release_year\"]  = pd.to_numeric(df[\"release_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df[\"release_month\"] = pd.to_numeric(df[\"release_month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# ì¥ë¥´ íŒŒì‹± -> ë¦¬ìŠ¤íŠ¸\n",
    "def parse_genres(x):\n",
    "    if isinstance(x, list): return [str(t).strip() for t in x if str(t).strip()]\n",
    "    if pd.isna(x): return []\n",
    "    s = str(x).strip()\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            val = ast.literal_eval(s)\n",
    "            out = []\n",
    "            for item in val:\n",
    "                if isinstance(item, dict):\n",
    "                    out.append(item.get(\"name\") or item.get(\"genreNm\") or str(item))\n",
    "                else:\n",
    "                    out.append(str(item).strip())\n",
    "            return [g for g in out if g]\n",
    "        except Exception:\n",
    "            pass\n",
    "    if \",\" in s:\n",
    "        return [t.strip() for t in s.split(\",\") if t.strip()]\n",
    "    return [s] if s else []\n",
    "\n",
    "if \"genres\" not in df.columns:\n",
    "    df[\"genres\"] = \"[]\"\n",
    "df[\"genres\"] = df[\"genres\"].apply(parse_genres)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í˜„í™©(í›„) â€” ë¦¬ìŠ¤íŠ¸ ìƒíƒœì—ì„œ ê³„ì‚°\n",
    "na_after = df.isna().sum().rename(\"na_after\")\n",
    "summary = pd.concat([na_before, na_after], axis=1).fillna(0).astype(int)\n",
    "summary[\"delta\"] = summary[\"na_after\"] - summary[\"na_before\"]\n",
    "\n",
    "print(\"\\nì •ë¦¬ í›„ shape:\", df.shape)\n",
    "print(\"\\nì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ë³€í™”:\")\n",
    "print(summary.sort_index())\n",
    "\n",
    "# === ì €ì¥ìš©: genresë¥¼ \"['ì½”ë¯¸ë””', 'ë“œë¼ë§ˆ']\" í˜•íƒœì˜ ë¬¸ìì—´ë¡œ ë³€í™˜ ===\n",
    "def list_to_literal_str(lst):\n",
    "    # ë‚´ë¶€ ì‘ì€ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„\n",
    "    safe = [str(x).replace(\"'\", \"\\\\'\") for x in (lst or [])]\n",
    "    return \"[\" + \", \".join(f\"'{x}'\" for x in safe) + \"]\"\n",
    "\n",
    "df_to_save = df.copy()\n",
    "df_to_save[\"genres\"] = df_to_save[\"genres\"].apply(list_to_literal_str)\n",
    "\n",
    "os.makedirs(os.path.dirname(PATH_OUT), exist_ok=True)\n",
    "df_to_save.to_csv(PATH_OUT, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nì €ì¥ ì™„ë£Œ â†’ {PATH_OUT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2b075",
   "metadata": {},
   "source": [
    "## ë„¤ì´ë²„ ë„¤í‹°ì¦Œ í‰ì , ë¹„í‰ê°€ í‰ì  ë°ì´í„° ìˆ˜ì§‘\n",
    "- ë„¤í‹°ì¦Œ í‰ì ì€ ì‹¤ê´€ëŒê°ì´ ì•„ë‹Œ ê´€ëŒê°ë„ í‰ì ì„ ë‚¨ê¸¸ ìˆ˜ ìˆìŒ.\n",
    "- í‰ë¡ ê°€ì˜ í‰ê·  í‰ì ê³¼ ì¸ì› ìˆ˜ë¥¼ êµ¬í•¨.\n",
    "- ë„¤ì´ë²„ì— ì§ì ‘ í¬ë¡¤ë§ì´ ì–´ë ¤ìš´ ì˜í™”ëŠ” ì§ì ‘ ê²€ìƒ‰ì„ í†µí•´ ë°ì´í„° ìˆ˜ì§‘. `ratings.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c970214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì™„ë£Œ! naver_ratings.csv ì €ì¥ë¨.\n"
     ]
    }
   ],
   "source": [
    "# build_naver_ratings.ipynb\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import urllib.parse\n",
    "\n",
    "# ğŸ¬ ë„¤ê°€ ê°€ì§„ ì˜í™” ë¦¬ìŠ¤íŠ¸\n",
    "titles = []\n",
    "\n",
    "base_url = \"https://movie.naver.com\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, title in enumerate(titles, 1):\n",
    "    try:\n",
    "        # ğŸ” ê²€ìƒ‰ì–´ ì•ˆì „í•˜ê²Œ ì¸ì½”ë”©\n",
    "        query = urllib.parse.quote(title)\n",
    "        search_url = f\"https://movie.naver.com/movie/search/result.naver?query={query}&section=all&ie=utf8\"\n",
    "\n",
    "        # ê²€ìƒ‰ í˜ì´ì§€ ìš”ì²­\n",
    "        res = requests.get(search_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì²« ë²ˆì§¸ ì˜í™” ë§í¬ ì¶”ì¶œ\n",
    "        movie_tag = soup.select_one(\".search_list_1 ul li dt a\")\n",
    "        if not movie_tag:\n",
    "            print(f\"[{idx}/{len(titles)}] {title} â†’ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\")\n",
    "            continue\n",
    "\n",
    "        movie_url = base_url + movie_tag[\"href\"]\n",
    "\n",
    "        # ì˜í™” ìƒì„¸ í˜ì´ì§€ ìš”ì²­\n",
    "        res = requests.get(movie_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # í‰ì , ì°¸ì—¬ì ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "        score_tag = soup.select_one(\".star_score em\")\n",
    "        count_tag = soup.select_one(\".score_total em\")\n",
    "\n",
    "        score = score_tag.text if score_tag else \"N/A\"\n",
    "        count = count_tag.text.replace(\",\", \"\") if count_tag else \"0\"\n",
    "\n",
    "        results.append({\"ì œëª©\": title, \"í‰ì \": score, \"ì°¸ì—¬ììˆ˜\": count})\n",
    "        print(f\"[{idx}/{len(titles)}] {title} â†’ í‰ì  {score}, ì°¸ì—¬ì {count}\")\n",
    "\n",
    "        # ğŸ”’ ì°¨ë‹¨ ë°©ì§€: 1~3ì´ˆ ëœë¤ ëŒ€ê¸°\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {title}: {e}\")\n",
    "\n",
    "# âœ… ë°ì´í„°í”„ë ˆì„ ì €ì¥\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"./data/raw/naver_ratings.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"ì™„ë£Œ! ./data/raw/naver_ratings.csv ì €ì¥ë¨.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33260f00",
   "metadata": {},
   "source": [
    "## ì˜í™” ê°ë…ê³¼ ì˜í™” ë°°ìš° ë°ì´í„° ìˆ˜ì§‘í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aee9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ë²ˆ ë°°ì¹˜: 927í¸ / ë‚¨ì€ 0í¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KOBIS credits (ko):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 384/927 [05:16<07:34,  1.19it/s]"
     ]
    }
   ],
   "source": [
    "# build_kobis_with_credits.ipynb\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ì…ë ¥:  ./data/raw/kobis_weekly_clean.csv  (movie_id = KOBIS movieCd)\n",
    "ì¶œë ¥1: ./data/raw/kobis_credits_partial.csv   (ì§„í–‰ ì¤‘ ìºì‹œ)\n",
    "ì¶œë ¥2: ./data/raw/kobis_with_credits.csv   (ì›ë³¸ + ê°ë…/ë°°ìš° í•œê¸€ ì´ë¦„ append)\n",
    "\n",
    "- ê°ë…: 1ëª…(ëª©ë¡ì˜ ì²« ê°ë…)\n",
    "- ë°°ìš°: castOrd ê¸°ì¤€ ìƒìœ„ 10ëª… (ì—†ìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ ìˆœì„œ ê¸°ì¤€)\n",
    "- ì´ë¦„: ëª¨ë‘ í•œêµ­ì–´(peopleNm) ì‚¬ìš©\n",
    "- ì¬ì‹¤í–‰ ì‹œ ì´ë¯¸ ì²˜ë¦¬í•œ movie_idëŠ” ê±´ë„ˆë›°ê³  ì´ì–´ì„œ ìˆ˜ì§‘\n",
    "\"\"\"\n",
    "\n",
    "import os, time, json, requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlencode\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---------------- ì„¤ì • ----------------\n",
    "IN_PATH   = \"./data/raw/kobis_weekly_clean.csv\"\n",
    "OUT_DIR   = \"./data/raw\"\n",
    "OUT_PART  = f\"{OUT_DIR}/kobis_credits_partial.csv\"     # movie_id, director_name_ko, cast_names_ko\n",
    "OUT_FINAL = f\"{OUT_DIR}/kobis_with_credits.csv\"     # ì›ë³¸ + ë¶™ì´ê¸° ê²°ê³¼\n",
    "\n",
    "CAST_TOP_N   = 10\n",
    "MOVIES_PER_RUN = 1000         # í•˜ë£¨ ì¿¼í„° ê³ ë ¤, í•œ ë²ˆì— ì²˜ë¦¬í•  ìµœëŒ€ í¸ìˆ˜\n",
    "SLEEP   = 0.12               # í˜¸ì¶œ ê°„ ë”œë ˆì´\n",
    "TIMEOUT = 20\n",
    "RETRY   = 3\n",
    "\n",
    "# -------------- ì¸ì¦/ì—”ë“œí¬ì¸íŠ¸ --------------\n",
    "load_dotenv()\n",
    "KOBIS_KEY = os.getenv(\"KOFIC_API_KEY\") or os.getenv(\"KOBIS_KEY\")\n",
    "BASE = \"https://www.kobis.or.kr/kobisopenapi/webservice/rest\"\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------- ê³µí†µ HTTP --------------\n",
    "def kobis_get(path, params, retry=RETRY):\n",
    "    if not KOBIS_KEY:\n",
    "        raise SystemExit(\"âŒ .envì— KOFIC_API_KEY(=KOBIS_KEY)ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    q = {\"key\": KOBIS_KEY, **params}\n",
    "    url = f\"{BASE}{path}.json?{urlencode(q)}\"\n",
    "    last = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=TIMEOUT)\n",
    "            if r.status_code in (429,500,502,503,504):\n",
    "                time.sleep(min(2**i, 8)); continue\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if data.get(\"faultInfo\"):\n",
    "                fi = data[\"faultInfo\"]\n",
    "                # ë©”ì‹œì§€ì™€ URLì„ í•¨ê»˜ ë³´ì—¬ì£¼ë˜, ì§„í–‰ì€ ì¤‘ë‹¨/ìŠ¤í‚µ\n",
    "                raise RuntimeError(f\"KOBIS fault: {fi.get('message')} (code={fi.get('errorCode')})\\nURL: {url}\")\n",
    "            time.sleep(SLEEP)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            if i == retry - 1:\n",
    "                raise\n",
    "            time.sleep(min(2**i, 8))\n",
    "    raise RuntimeError(last)\n",
    "\n",
    "# -------------- ë‹¨ì¼ ì˜í™” í¬ë ˆë”§ ìˆ˜ì§‘ --------------\n",
    "def safe_int(x, default=999999):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def fetch_credits_kor(movie_cd: str):\n",
    "    \"\"\"KOBIS movieCdë¡œ ê°ë… 1ëª… + ë°°ìš° ìƒìœ„ 10ëª…(í•œê¸€ëª…) ì¶”ì¶œ\"\"\"\n",
    "    js = kobis_get(\"/movie/searchMovieInfo\", {\"movieCd\": movie_cd})\n",
    "    info = js.get(\"movieInfoResult\", {}).get(\"movieInfo\", {}) or {}\n",
    "\n",
    "    # ê°ë…(ëª©ë¡ ì²« ê°ë… 1ëª…)\n",
    "    directors = info.get(\"directors\") or []\n",
    "    director_ko = \"\"\n",
    "    if directors:\n",
    "        # peopleNm: í•œê¸€ëª…, peopleNmEn: ì˜ë¬¸ëª…\n",
    "        director_ko = (directors[0].get(\"peopleNm\") or \"\").strip()\n",
    "\n",
    "    # ë°°ìš°(castOrd ì˜¤ë¦„ì°¨ìˆœ ìƒìœ„ N)\n",
    "    actors = info.get(\"actors\") or []\n",
    "    # castOrdê°€ ì—†ê±°ë‚˜ ë¹„ë©´ í° ìˆ˜ë¡œ ì²˜ë¦¬ â†’ ë¦¬ìŠ¤íŠ¸ ìˆœì„œ ë³´ì¡´\n",
    "    actors_sorted = sorted(\n",
    "        actors,\n",
    "        key=lambda a: safe_int(a.get(\"castOrd\"), default=999999)\n",
    "    )\n",
    "    cast_top = []\n",
    "    for a in actors_sorted[:CAST_TOP_N]:\n",
    "        nm = (a.get(\"peopleNm\") or \"\").strip()  # í•œê¸€ëª…\n",
    "        if nm:\n",
    "            cast_top.append(nm)\n",
    "    cast_names_ko = \"|\".join(cast_top)\n",
    "\n",
    "    return {\n",
    "        \"movie_id\": movie_cd,\n",
    "        \"director_name_ko\": director_ko,\n",
    "        \"cast_names_ko\": cast_names_ko\n",
    "    }\n",
    "\n",
    "# -------------- ë©”ì¸ --------------\n",
    "def main():\n",
    "    # ì…ë ¥ ë¡œë“œ\n",
    "    base = pd.read_csv(IN_PATH, dtype={\"movie_id\": str})\n",
    "    if \"movie_id\" not in base.columns:\n",
    "        raise SystemExit(\"âŒ ì…ë ¥ CSVì— movie_id ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # partial(ì§„í–‰ ìºì‹œ) ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    if os.path.exists(OUT_PART):\n",
    "        part = pd.read_csv(OUT_PART, dtype={\"movie_id\": str})\n",
    "    else:\n",
    "        part = pd.DataFrame(columns=[\"movie_id\", \"director_name_ko\", \"cast_names_ko\"])\n",
    "\n",
    "    done_ids = set(part[\"movie_id\"].tolist())\n",
    "    all_ids  = [mid for mid in base[\"movie_id\"].astype(str).tolist() if isinstance(mid, str)]\n",
    "    todo_ids = [mid for mid in all_ids if mid not in done_ids]\n",
    "\n",
    "    if not todo_ids:\n",
    "        print(\"âœ… ìƒˆë¡œ ìˆ˜ì§‘í•  ëŒ€ìƒ ì—†ìŒ. ë³‘í•©ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        batch = todo_ids[:MOVIES_PER_RUN]\n",
    "        print(f\"ì´ë²ˆ ë°°ì¹˜: {len(batch)}í¸ / ë‚¨ì€ {len(todo_ids) - len(batch)}í¸\")\n",
    "\n",
    "        rows = []\n",
    "        for mid in tqdm(batch, desc=\"KOBIS credits (ko)\"):\n",
    "            try:\n",
    "                rows.append(fetch_credits_kor(mid))\n",
    "            except Exception as e:\n",
    "                # ì—ëŸ¬ëŠ” ìŠ¤í‚µí•˜ê³  ì§„í–‰(ì¿¼í„° ì´ˆê³¼/ê°„í— ì˜¤ë¥˜ ë“±)\n",
    "                print(\"skip\", mid, e)\n",
    "\n",
    "        if rows:\n",
    "            add = pd.DataFrame(rows)\n",
    "            # partialì— append (ì¤‘ë³µ ì œê±°)\n",
    "            merged = pd.concat([part, add], ignore_index=True)\n",
    "            merged = merged.drop_duplicates(subset=[\"movie_id\"], keep=\"last\")\n",
    "            merged.to_csv(OUT_PART, index=False, encoding=\"utf-8-sig\")\n",
    "            part = merged\n",
    "\n",
    "    # ìµœì¢… ë³‘í•©(ì›ë³¸ + credits)\n",
    "    final = base.merge(part, on=\"movie_id\", how=\"left\")\n",
    "    final.to_csv(OUT_FINAL, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {OUT_FINAL} (rows={len(final):,})\")\n",
    "    # ì§„í–‰ ìƒí™© ì°¸ê³ (ì˜µì…˜)\n",
    "    got = final[\"director_name_ko\"].notna().sum()\n",
    "    print(f\"   â”” ê°ë…/ë°°ìš° ì±„ì›Œì§„ í–‰: {got:,} / {len(final):,}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74041396",
   "metadata": {},
   "source": [
    "## ê¸°ì¡´ íŒŒì¼ì— ë„¤ì´ë²„ ë„¤í‹°ì¦Œ í‰ì  / ë¹„í‰ê°€ í‰ì  ì»¬ëŸ¼ ë¶™ì´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8eb4da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: ./data/raw/kobis_with_ratings.csv | rows: 927 | matched: 925\n"
     ]
    }
   ],
   "source": [
    "# build_kobis_with_ratings.ipynb\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, pandas as pd\n",
    "\n",
    "kobis_path  = \"./data/raw/kobis_with_credits.csv\"      # ë°©ê¸ˆ ì˜¬ë¦° íŒŒì¼\n",
    "naver_path  = \"./data/raw/naver_ratings.csv\"           # ë„¤ì´ë²„ ìŠ¤í¬ë© ê²°ê³¼\n",
    "out_path    = \"./data/raw/kobis_with_ratings.csv\"\n",
    "\n",
    "kobis = pd.read_csv(kobis_path)\n",
    "naver = pd.read_csv(naver_path)\n",
    "\n",
    "# ì œëª© ì •ê·œí™”(ê³µë°± ì œê±° ë“±)ë¡œ ë§¤ì¹­ë¥  ì˜¬ë¦¬ê¸°\n",
    "def norm(s): return str(s).strip().replace(\" \", \"\")\n",
    "kobis[\"__t\"] = kobis[\"title\"].map(norm)\n",
    "naver[\"__t\"] = naver[\"ì œëª©\"].map(norm)\n",
    "\n",
    "# ë„¤ì´ë²„ ì»¬ëŸ¼ ì˜ë¬¸ìœ¼ë¡œ ë¦¬ë„¤ì„\n",
    "naver_ren = naver.rename(columns={\n",
    "    \"ë„¤í‹°ì¦Œì ìˆ˜\": \"vote_average_naver\",\n",
    "    \"ë„¤í‹°ì¦Œí‰ê°€ìˆ˜\": \"vote_count_naver\",\n",
    "    \"ì „ë¬¸ê°€í‰ì í‰ê· \": \"critic_average\",\n",
    "    \"ì „ë¬¸ê°€ìˆ˜\": \"critic_count\",\n",
    "})\n",
    "\n",
    "# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ê°€ì ¸ì™€ ë³‘í•©\n",
    "merged = kobis.merge(\n",
    "    naver_ren[[\"__t\",\"vote_average_naver\",\"vote_count_naver\",\"critic_average\",\"critic_count\"]],\n",
    "    on=\"__t\", how=\"left\"\n",
    ")\n",
    "\n",
    "# ê¸°ì¡´ TMDB ìŠ¤íƒ€ì¼ ì»¬ëŸ¼ ì±„ìš°ê¸°(ì—†ìœ¼ë©´ ìƒì„±)\n",
    "if \"vote_average\" in merged.columns:\n",
    "    merged[\"vote_average\"] = merged[\"vote_average\"].fillna(merged[\"vote_average_naver\"])\n",
    "else:\n",
    "    merged[\"vote_average\"] = merged[\"vote_average_naver\"]\n",
    "\n",
    "if \"vote_count\" in merged.columns:\n",
    "    merged[\"vote_count\"] = merged[\"vote_count\"].fillna(merged[\"vote_count_naver\"])\n",
    "else:\n",
    "    merged[\"vote_count\"] = merged[\"vote_count_naver\"]\n",
    "\n",
    "# ì‘ì—…ìš© í‚¤ ì œê±° í›„ ì €ì¥\n",
    "merged = merged.drop(columns=[\"__t\"])\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "merged.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"saved:\", out_path,\n",
    "      \"| rows:\", len(merged),\n",
    "      \"| matched:\", merged[\"vote_average_naver\"].notna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128fa425",
   "metadata": {},
   "source": [
    "## ì¥ë¥´ Explode\n",
    "- ì˜í™” ì¥ë¥´ë³„ ë¶„ì„ì„ ìœ„í•´ explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "591b4aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ê²½ë¡œ: ./data/processed/kobis_weekly_final.csv\n",
      "ì›ë³¸/í­ë°œ í›„: (927, 23) â†’ (1554, 23)\n"
     ]
    }
   ],
   "source": [
    "import os, ast, pandas as pd\n",
    "\n",
    "# 1) ì›ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "in_path = \"./data/processed/kobis_weekly_final.csv\"\n",
    "if not in_path:\n",
    "    raise FileNotFoundError(\"ì…ë ¥ CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì‹¤ì œ ì €ì¥ ê²½ë¡œ(ì–¸ë”ìŠ¤ì½”ì–´ ì—¬ë¶€ í¬í•¨)ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "print(\"ì‚¬ìš© ê²½ë¡œ:\", in_path)\n",
    "df_raw = pd.read_csv(in_path, dtype={\"movie_id\": str})\n",
    "\n",
    "# 2) genresë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±\n",
    "def parse_genres(x):\n",
    "    if isinstance(x, list): return x\n",
    "    if pd.isna(x): return []\n",
    "    s = str(x).strip()\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            vals = ast.literal_eval(s)\n",
    "            out = []\n",
    "            for v in vals:\n",
    "                if isinstance(v, dict):\n",
    "                    out.append(v.get(\"name\") or v.get(\"genreNm\") or str(v))\n",
    "                else:\n",
    "                    out.append(str(v).strip())\n",
    "            return [g for g in out if g]\n",
    "        except Exception:\n",
    "            pass\n",
    "    if \",\" in s:\n",
    "        return [t.strip() for t in s.split(\",\") if t.strip()]\n",
    "    return [s] if s else []\n",
    "\n",
    "df_raw[\"genres\"] = df_raw[\"genres\"].apply(parse_genres)\n",
    "\n",
    "# 3) í•„ìš” ì‹œ explode (ì˜µì…˜)\n",
    "df_exploded = df_raw.explode(\"genres\").query(\"genres.notna() and genres.str.strip() != ''\")\n",
    "print(\"ì›ë³¸/í­ë°œ í›„:\", df_raw.shape, \"â†’\", df_exploded.shape)\n",
    "\n",
    "# 4) ì €ì¥ ì˜ˆì‹œ\n",
    "df_exploded.to_csv(\"./data/processed/kobis_genre_exploded.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
