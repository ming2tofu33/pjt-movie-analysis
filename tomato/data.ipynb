{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259b23ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ…API KEY and TOKEN are set!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TMDB_API_KEY = os.getenv('TMDB_API_KEY')\n",
    "TMDB_API_TOKEN = os.getenv('TMDB_API_TOKEN')\n",
    "\n",
    "if TMDB_API_KEY and TMDB_API_TOKEN:\n",
    "    print('âœ…API KEY and TOKEN are set!')\n",
    "else:\n",
    "    print('âŒAPI KEY and TOKEN 404')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601c7378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) ID ìˆ˜ì§‘ (ğŸ‡°ğŸ‡· ì œì‘ âˆ© ğŸ‡°ğŸ‡· ê·¹ì¥ 2|3)â€¦\n",
      "â†’ ID ìˆ˜ì§‘ ë²”ìœ„: 2005-01-01 ~ 2025-06-30\n",
      "   ì˜ˆìƒ ì´ í˜ì´ì§€: 234 (ì´ í¸ìˆ˜ ì˜ˆìƒ: 4670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†’ ê³ ìœ  ID ìˆ˜: 4,670\n",
      "2) ìƒì„¸ ìˆ˜ì§‘ ì¤‘â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3) ì •ê·œí™” ë° CSV ì €ì¥â€¦\n",
      "âœ… ì™„ë£Œ: data/processed/tmdb_kr_theatrical_2005_2025.csv (rows=4,670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "í•œêµ­ì—ì„œ ì œì‘ + í•œêµ­ ê·¹ì¥ ê°œë´‰(2|3) ì˜í™”ë§Œ ìˆ˜ì§‘ â†’ CSV ì €ì¥(ì§„í–‰ë¥  í‘œì‹œ)\n",
    "ê¸°ê°„: 2005-01-01 ~ 2025-06-30\n",
    "\"\"\"\n",
    "\n",
    "import os, time, datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ===================== ì„¤ì • =====================\n",
    "START_DATE = \"2005-01-01\"\n",
    "END_DATE   = \"2025-06-30\"\n",
    "\n",
    "LANG = \"ko-KR\"\n",
    "BASE = \"https://api.themoviedb.org/3\"\n",
    "SLEEP = 0.05                       # ìš”ì²­ ê°„ ë”œë ˆì´\n",
    "TIMEOUT = 30\n",
    "\n",
    "INCLUDE_ADULT = False              # ì„±ì¸ë¬¼ í¬í•¨í•˜ë ¤ë©´ True\n",
    "INCLUDE_VIDEO = False              # ë³´í†µ False ê¶Œì¥\n",
    "VOTE_COUNT_MIN = 20                # ë„ˆë¬´ ë§ˆì´ë„ˆ ì‘í’ˆ ì œê±°(ì›í•˜ë©´ 20/50 ë“±ìœ¼ë¡œ ì¡°ì •)\n",
    "\n",
    "OUT_CSV = \"data/processed/tmdb_kr_theatrical_2005_2025.csv\"\n",
    "\n",
    "# ===================== ì¤€ë¹„ =====================\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"TMDB_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise SystemExit(\"âŒ TMDB_API_KEYê°€ í™˜ê²½ë³€ìˆ˜(.env)ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
    "\n",
    "# ===================== ê³µí†µ ìœ í‹¸ =====================\n",
    "def get_json(url: str, params: dict, tries: int = 3):\n",
    "    for i in range(tries):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=TIMEOUT)\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                time.sleep(min(2**i, 8)); continue\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except requests.RequestException:\n",
    "            if i == tries - 1:\n",
    "                raise\n",
    "            time.sleep(min(2**i, 8))\n",
    "    raise RuntimeError(\"Unreachable\")\n",
    "\n",
    "def common_params():\n",
    "    return {\n",
    "        \"api_key\": API_KEY,\n",
    "        \"language\": LANG,\n",
    "        \"include_adult\": str(INCLUDE_ADULT).lower(),\n",
    "        \"include_video\": str(INCLUDE_VIDEO).lower(),\n",
    "        \"with_vote_count.gte\": VOTE_COUNT_MIN,\n",
    "        \"with_origin_country\": \"KR\",     # ğŸ‡°ğŸ‡· ì œì‘êµ­ í•œêµ­\n",
    "        \"region\": \"KR\",                  # ğŸ‡°ğŸ‡· ê°œë´‰ ì§€ì—­ í•œêµ­\n",
    "        \"with_release_type\": \"2|3\",      # ê·¹ì¥ ê°œë´‰(ì œí•œ/ì •ì‹)\n",
    "        \"sort_by\": \"release_date.asc\",   # í•œêµ­ ê°œë´‰ì¼ ê¸°ì¤€ ì •ë ¬\n",
    "        # release_date.gte/lteëŠ” í˜¸ì¶œ ì‹œ ì£¼ì…\n",
    "    }\n",
    "\n",
    "# ===================== 1) ID ìˆ˜ì§‘ =====================\n",
    "def discover_total_pages(date_gte: str, date_lte: str) -> int:\n",
    "    p = common_params()\n",
    "    p.update({\"release_date.gte\": date_gte, \"release_date.lte\": date_lte, \"page\": 1})\n",
    "    js = get_json(f\"{BASE}/discover/movie\", p)\n",
    "    return int(js.get(\"total_pages\", 1)), int(js.get(\"total_results\", 0)), js.get(\"results\", [])\n",
    "\n",
    "def discover_ids_for_range(date_gte: str, date_lte: str, pbar=None):\n",
    "    \"\"\"ë²”ìœ„ë¥¼ /discoverë¡œ ìˆ˜ì§‘. total_pages<=500ì´ë©´ í•œ ë²ˆì—, ì•„ë‹ˆë©´ í˜¸ì¶œìê°€ ìŠ¬ë¼ì´ìŠ¤.\"\"\"\n",
    "    p = common_params()\n",
    "    p.update({\"release_date.gte\": date_gte, \"release_date.lte\": date_lte, \"page\": 1})\n",
    "    first = get_json(f\"{BASE}/discover/movie\", p)\n",
    "    total_pages = int(first.get(\"total_pages\", 1))\n",
    "    ids = [m[\"id\"] for m in first.get(\"results\", [])]\n",
    "    if pbar: pbar.update(1)\n",
    "\n",
    "    for page in range(2, min(total_pages, 500) + 1):\n",
    "        p[\"page\"] = page\n",
    "        js = get_json(f\"{BASE}/discover/movie\", p)\n",
    "        ids.extend([m[\"id\"] for m in js.get(\"results\", [])])\n",
    "        if pbar: pbar.update(1)\n",
    "        time.sleep(SLEEP)\n",
    "    capped = total_pages > 500\n",
    "    return ids, capped, total_pages\n",
    "\n",
    "def year_slices(start: str, end: str):\n",
    "    s = dt.date.fromisoformat(start); e = dt.date.fromisoformat(end)\n",
    "    for y in range(s.year, e.year + 1):\n",
    "        y0 = dt.date(y, 1, 1); y1 = dt.date(y, 12, 31)\n",
    "        if y0 < s: y0 = s\n",
    "        if y1 > e: y1 = e\n",
    "        yield y0.isoformat(), y1.isoformat()\n",
    "\n",
    "def collect_all_ids():\n",
    "    print(\"â†’ ID ìˆ˜ì§‘ ë²”ìœ„:\", START_DATE, \"~\", END_DATE)\n",
    "    tp, tr, first_results = discover_total_pages(START_DATE, END_DATE)\n",
    "    print(f\"   ì˜ˆìƒ ì´ í˜ì´ì§€: {tp} (ì´ í¸ìˆ˜ ì˜ˆìƒ: {tr})\")\n",
    "\n",
    "    if tp <= 500:\n",
    "        # ì „ êµ¬ê°„ì„ í•œ ë²ˆì— ìˆ˜ì§‘ (í˜ì´ì§€ ê¸°ë°˜ ì§„í–‰ë°”)\n",
    "        ids = [m[\"id\"] for m in first_results]\n",
    "        with tqdm(total=tp, desc=\"Discover pages (all range)\", leave=False) as bar:\n",
    "            bar.update(1)  # page=1 ì²˜ë¦¬ ë°˜ì˜\n",
    "            more_ids, _, _ = discover_ids_for_range(START_DATE, END_DATE, pbar=bar)\n",
    "            ids = more_ids  # discover_ids_for_range ì•ˆì—ì„œ page1ë¶€í„° ë‹¤ì‹œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ê·¸ê±¸ ì‚¬ìš©\n",
    "        return sorted(set(ids))\n",
    "\n",
    "    # 500 ì´ˆê³¼ â†’ ì—° ë‹¨ìœ„ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜ì§‘ (ì—° ì „ì²´ í˜ì´ì§€ í•©ì‚°í•´ì„œ ì§„í–‰ë°” í‘œì‹œ)\n",
    "    # ë¨¼ì € ê° ì—°ë„ì˜ í˜ì´ì§€ ìˆ˜ë¥¼ íŒŒì•…í•´ í•©ì‚°\n",
    "    total_pages_sum = 0\n",
    "    year_meta = []\n",
    "    for yg, yl in year_slices(START_DATE, END_DATE):\n",
    "        pages, _, _ = discover_total_pages(yg, yl)\n",
    "        year_meta.append((yg, yl, pages))\n",
    "        total_pages_sum += min(pages, 500)\n",
    "    print(f\"   ì—° ë‹¨ìœ„ ìŠ¬ë¼ì´ìŠ¤ ì§„í–‰ (ì´ í˜ì´ì§€ í•©ì‚°: {total_pages_sum})\")\n",
    "\n",
    "    all_ids = set()\n",
    "    with tqdm(total=total_pages_sum, desc=\"Discover pages (by year)\", leave=False) as bar:\n",
    "        for yg, yl, pages in year_meta:\n",
    "            ids_y, _, _ = discover_ids_for_range(yg, yl, pbar=bar)\n",
    "            all_ids.update(ids_y)\n",
    "            time.sleep(SLEEP)\n",
    "    return sorted(all_ids)\n",
    "\n",
    "# ===================== 2) ìƒì„¸ ìˆ˜ì§‘ =====================\n",
    "def fetch_detail(mid: int):\n",
    "    params = {\"api_key\": API_KEY, \"language\": LANG}\n",
    "    try:\n",
    "        js = get_json(f\"{BASE}/movie/{mid}\", params)\n",
    "        time.sleep(SLEEP)\n",
    "        return js\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "# ===================== 3) ì •ê·œí™” â†’ CSV =====================\n",
    "def parse_genres(val):\n",
    "    return [x.get(\"name\") for x in val] if isinstance(val, list) else []\n",
    "\n",
    "def normalize_rows(rows):\n",
    "    df = pd.json_normalize(rows)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"movie_id\": df.get(\"id\"),\n",
    "        \"title\": df.get(\"title\"),\n",
    "        \"original_title\": df.get(\"original_title\"),\n",
    "        \"original_language\": df.get(\"original_language\"),\n",
    "        \"release_date\": df.get(\"release_date\"),\n",
    "        \"runtime\": pd.to_numeric(df.get(\"runtime\"), errors=\"coerce\"),\n",
    "        \"budget\": pd.to_numeric(df.get(\"budget\"), errors=\"coerce\"),\n",
    "        \"revenue\": pd.to_numeric(df.get(\"revenue\"), errors=\"coerce\"),\n",
    "        \"vote_average\": pd.to_numeric(df.get(\"vote_average\"), errors=\"coerce\"),\n",
    "        \"vote_count\": pd.to_numeric(df.get(\"vote_count\"), errors=\"coerce\"),\n",
    "        \"popularity\": pd.to_numeric(df.get(\"popularity\"), errors=\"coerce\"),\n",
    "        \"genres\": df.get(\"genres\").apply(parse_genres) if \"genres\" in df else [],\n",
    "        \"production_companies\": df.get(\"production_companies\").apply(\n",
    "            lambda xs: [x.get(\"name\") for x in xs] if isinstance(xs, list) else []\n",
    "        ) if \"production_companies\" in df else [],\n",
    "        \"production_countries\": df.get(\"production_countries\").apply(\n",
    "            lambda xs: [x.get(\"iso_3166_1\") for x in xs] if isinstance(xs, list) else []\n",
    "        ) if \"production_countries\" in df else [],\n",
    "    })\n",
    "    dt_series = pd.to_datetime(out[\"release_date\"], errors=\"coerce\")\n",
    "    out[\"release_year\"]  = dt_series.dt.year\n",
    "    out[\"release_month\"] = dt_series.dt.month\n",
    "    return out\n",
    "\n",
    "# ===================== ë©”ì¸ =====================\n",
    "def main():\n",
    "    print(\"1) ID ìˆ˜ì§‘ (ğŸ‡°ğŸ‡· ì œì‘ âˆ© ğŸ‡°ğŸ‡· ê·¹ì¥ 2|3)â€¦\")\n",
    "    ids = collect_all_ids()\n",
    "    print(f\"   â†’ ê³ ìœ  ID ìˆ˜: {len(ids):,}\")\n",
    "\n",
    "    print(\"2) ìƒì„¸ ìˆ˜ì§‘ ì¤‘â€¦\")\n",
    "    rows = []\n",
    "    with tqdm(total=len(ids), desc=\"Fetch details\", leave=False) as bar:\n",
    "        for mid in ids:\n",
    "            d = fetch_detail(mid)\n",
    "            if d: rows.append(d)\n",
    "            bar.update(1)\n",
    "\n",
    "    print(\"3) ì •ê·œí™” ë° CSV ì €ì¥â€¦\")\n",
    "    df = normalize_rows(rows)\n",
    "    df.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… ì™„ë£Œ: {OUT_CSV} (rows={len(df):,})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
