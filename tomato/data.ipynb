{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259b23ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅API KEY and TOKEN are set!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TMDB_API_KEY = os.getenv('TMDB_API_KEY')\n",
    "TMDB_API_TOKEN = os.getenv('TMDB_API_TOKEN')\n",
    "\n",
    "if TMDB_API_KEY and TMDB_API_TOKEN:\n",
    "    print('✅API KEY and TOKEN are set!')\n",
    "else:\n",
    "    print('❌API KEY and TOKEN 404')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601c7378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) ID 수집 (🇰🇷 제작 ∩ 🇰🇷 극장 2|3)…\n",
      "→ ID 수집 범위: 2005-01-01 ~ 2025-06-30\n",
      "   예상 총 페이지: 234 (총 편수 예상: 4672)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 192\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ 완료: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUT_CSV\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (rows=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 175\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m    174\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m1) ID 수집 (🇰🇷 제작 ∩ 🇰🇷 극장 2|3)…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     ids = \u001b[43mcollect_all_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   → 고유 ID 수: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m2) 상세 수집 중…\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mcollect_all_ids\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=tp, desc=\u001b[33m\"\u001b[39m\u001b[33mDiscover pages (all range)\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m bar:\n\u001b[32m    107\u001b[39m     bar.update(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# page=1 처리 반영\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     more_ids, _, _ = \u001b[43mdiscover_ids_for_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSTART_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     ids = more_ids  \u001b[38;5;66;03m# discover_ids_for_range 안에서 page1부터 다시 처리했으므로 그걸 사용\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(ids))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mdiscover_ids_for_range\u001b[39m\u001b[34m(date_gte, date_lte, pbar)\u001b[39m\n\u001b[32m     74\u001b[39m p = common_params()\n\u001b[32m     75\u001b[39m p.update({\u001b[33m\"\u001b[39m\u001b[33mrelease_date.gte\u001b[39m\u001b[33m\"\u001b[39m: date_gte, \u001b[33m\"\u001b[39m\u001b[33mrelease_date.lte\u001b[39m\u001b[33m\"\u001b[39m: date_lte, \u001b[33m\"\u001b[39m\u001b[33mpage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m})\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m first = \u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBASE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/discover/movie\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m total_pages = \u001b[38;5;28mint\u001b[39m(first.get(\u001b[33m\"\u001b[39m\u001b[33mtotal_pages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m     78\u001b[39m ids = [m[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m first.get(\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m, [])]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mget_json\u001b[39m\u001b[34m(url, params, tries)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tries):\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTIMEOUT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m r.status_code \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m429\u001b[39m, \u001b[32m500\u001b[39m, \u001b[32m502\u001b[39m, \u001b[32m503\u001b[39m, \u001b[32m504\u001b[39m):\n\u001b[32m     42\u001b[39m             time.sleep(\u001b[38;5;28mmin\u001b[39m(\u001b[32m2\u001b[39m**i, \u001b[32m8\u001b[39m)); \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\connection.py:790\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m     \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[32m    788\u001b[39m     server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# If an error occurs during connection/handshake we may need to release\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# our lock so another connection can probe the origin.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\connection.py:969\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[32m    967\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    983\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:480\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n\u001b[32m    476\u001b[39m         context.load_cert_chain(certfile, keyfile, key_password)\n\u001b[32m    478\u001b[39m context.set_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m ssl_sock = \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:524\u001b[39m, in \u001b[36m_ssl_wrap_socket_impl\u001b[39m\u001b[34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[39m\n\u001b[32m    521\u001b[39m     SSLTransport._validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1076\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1073\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m timeout == \u001b[32m0.0\u001b[39m:\n\u001b[32m   1074\u001b[39m                 \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[32m   1075\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1078\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1372\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout == \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[32m   1371\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28mself\u001b[39m.settimeout(timeout)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "한국에서 제작 + 한국 극장 개봉(2|3) 영화만 수집 → CSV 저장(진행률 표시)\n",
    "기간: 2005-01-01 ~ 2025-06-30\n",
    "\"\"\"\n",
    "\n",
    "import os, time, datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ===================== 설정 =====================\n",
    "START_DATE = \"2005-01-01\"\n",
    "END_DATE   = \"2025-06-30\"\n",
    "\n",
    "LANG = \"ko-KR\"\n",
    "BASE = \"https://api.themoviedb.org/3\"\n",
    "SLEEP = 0.05                       # 요청 간 딜레이\n",
    "TIMEOUT = 30\n",
    "\n",
    "INCLUDE_ADULT = False              # 성인물 포함하려면 True\n",
    "INCLUDE_VIDEO = False              # 보통 False 권장\n",
    "VOTE_COUNT_MIN = 10                # 너무 마이너 작품 제거(원하면 20/50 등으로 조정)\n",
    "\n",
    "OUT_CSV = \"data/processed/tmdb_kr_theatrical_2005_2025.csv\"\n",
    "\n",
    "# ===================== 준비 =====================\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"TMDB_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise SystemExit(\"❌ TMDB_API_KEY가 환경변수(.env)에 없습니다.\")\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
    "\n",
    "# ===================== 공통 유틸 =====================\n",
    "def get_json(url: str, params: dict, tries: int = 3):\n",
    "    for i in range(tries):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=TIMEOUT)\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                time.sleep(min(2**i, 8)); continue\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except requests.RequestException:\n",
    "            if i == tries - 1:\n",
    "                raise\n",
    "            time.sleep(min(2**i, 8))\n",
    "    raise RuntimeError(\"Unreachable\")\n",
    "\n",
    "def common_params():\n",
    "    return {\n",
    "        \"api_key\": API_KEY,\n",
    "        \"language\": LANG,\n",
    "        \"include_adult\": str(INCLUDE_ADULT).lower(),\n",
    "        \"include_video\": str(INCLUDE_VIDEO).lower(),\n",
    "        \"with_vote_count.gte\": VOTE_COUNT_MIN,\n",
    "        \"with_origin_country\": \"KR\",     # 🇰🇷 제작국 한국\n",
    "        \"region\": \"KR\",                  # 🇰🇷 개봉 지역 한국\n",
    "        \"with_release_type\": \"2|3\",      # 극장 개봉(제한/정식)\n",
    "        \"sort_by\": \"release_date.asc\",   # 한국 개봉일 기준 정렬\n",
    "        # release_date.gte/lte는 호출 시 주입\n",
    "    }\n",
    "\n",
    "# ===================== 1) ID 수집 =====================\n",
    "def discover_total_pages(date_gte: str, date_lte: str) -> int:\n",
    "    p = common_params()\n",
    "    p.update({\"release_date.gte\": date_gte, \"release_date.lte\": date_lte, \"page\": 1})\n",
    "    js = get_json(f\"{BASE}/discover/movie\", p)\n",
    "    return int(js.get(\"total_pages\", 1)), int(js.get(\"total_results\", 0)), js.get(\"results\", [])\n",
    "\n",
    "def discover_ids_for_range(date_gte: str, date_lte: str, pbar=None):\n",
    "    \"\"\"범위를 /discover로 수집. total_pages<=500이면 한 번에, 아니면 호출자가 슬라이스.\"\"\"\n",
    "    p = common_params()\n",
    "    p.update({\"release_date.gte\": date_gte, \"release_date.lte\": date_lte, \"page\": 1})\n",
    "    first = get_json(f\"{BASE}/discover/movie\", p)\n",
    "    total_pages = int(first.get(\"total_pages\", 1))\n",
    "    ids = [m[\"id\"] for m in first.get(\"results\", [])]\n",
    "    if pbar: pbar.update(1)\n",
    "\n",
    "    for page in range(2, min(total_pages, 500) + 1):\n",
    "        p[\"page\"] = page\n",
    "        js = get_json(f\"{BASE}/discover/movie\", p)\n",
    "        ids.extend([m[\"id\"] for m in js.get(\"results\", [])])\n",
    "        if pbar: pbar.update(1)\n",
    "        time.sleep(SLEEP)\n",
    "    capped = total_pages > 500\n",
    "    return ids, capped, total_pages\n",
    "\n",
    "def year_slices(start: str, end: str):\n",
    "    s = dt.date.fromisoformat(start); e = dt.date.fromisoformat(end)\n",
    "    for y in range(s.year, e.year + 1):\n",
    "        y0 = dt.date(y, 1, 1); y1 = dt.date(y, 12, 31)\n",
    "        if y0 < s: y0 = s\n",
    "        if y1 > e: y1 = e\n",
    "        yield y0.isoformat(), y1.isoformat()\n",
    "\n",
    "def collect_all_ids():\n",
    "    print(\"→ ID 수집 범위:\", START_DATE, \"~\", END_DATE)\n",
    "    tp, tr, first_results = discover_total_pages(START_DATE, END_DATE)\n",
    "    print(f\"   예상 총 페이지: {tp} (총 편수 예상: {tr})\")\n",
    "\n",
    "    if tp <= 500:\n",
    "        # 전 구간을 한 번에 수집 (페이지 기반 진행바)\n",
    "        ids = [m[\"id\"] for m in first_results]\n",
    "        with tqdm(total=tp, desc=\"Discover pages (all range)\", leave=False) as bar:\n",
    "            bar.update(1)  # page=1 처리 반영\n",
    "            more_ids, _, _ = discover_ids_for_range(START_DATE, END_DATE, pbar=bar)\n",
    "            ids = more_ids  # discover_ids_for_range 안에서 page1부터 다시 처리했으므로 그걸 사용\n",
    "        return sorted(set(ids))\n",
    "\n",
    "    # 500 초과 → 연 단위 슬라이스 수집 (연 전체 페이지 합산해서 진행바 표시)\n",
    "    # 먼저 각 연도의 페이지 수를 파악해 합산\n",
    "    total_pages_sum = 0\n",
    "    year_meta = []\n",
    "    for yg, yl in year_slices(START_DATE, END_DATE):\n",
    "        pages, _, _ = discover_total_pages(yg, yl)\n",
    "        year_meta.append((yg, yl, pages))\n",
    "        total_pages_sum += min(pages, 500)\n",
    "    print(f\"   연 단위 슬라이스 진행 (총 페이지 합산: {total_pages_sum})\")\n",
    "\n",
    "    all_ids = set()\n",
    "    with tqdm(total=total_pages_sum, desc=\"Discover pages (by year)\", leave=False) as bar:\n",
    "        for yg, yl, pages in year_meta:\n",
    "            ids_y, _, _ = discover_ids_for_range(yg, yl, pbar=bar)\n",
    "            all_ids.update(ids_y)\n",
    "            time.sleep(SLEEP)\n",
    "    return sorted(all_ids)\n",
    "\n",
    "# ===================== 2) 상세 수집 =====================\n",
    "def fetch_detail(mid: int):\n",
    "    params = {\"api_key\": API_KEY, \"language\": LANG}\n",
    "    try:\n",
    "        js = get_json(f\"{BASE}/movie/{mid}\", params)\n",
    "        time.sleep(SLEEP)\n",
    "        return js\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "# ===================== 3) 정규화 → CSV =====================\n",
    "def parse_genres(val):\n",
    "    return [x.get(\"name\") for x in val] if isinstance(val, list) else []\n",
    "\n",
    "def normalize_rows(rows):\n",
    "    df = pd.json_normalize(rows)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"movie_id\": df.get(\"id\"),\n",
    "        \"title\": df.get(\"title\"),\n",
    "        \"original_title\": df.get(\"original_title\"),\n",
    "        \"original_language\": df.get(\"original_language\"),\n",
    "        \"release_date\": df.get(\"release_date\"),\n",
    "        \"runtime\": pd.to_numeric(df.get(\"runtime\"), errors=\"coerce\"),\n",
    "        \"budget\": pd.to_numeric(df.get(\"budget\"), errors=\"coerce\"),\n",
    "        \"revenue\": pd.to_numeric(df.get(\"revenue\"), errors=\"coerce\"),\n",
    "        \"vote_average\": pd.to_numeric(df.get(\"vote_average\"), errors=\"coerce\"),\n",
    "        \"vote_count\": pd.to_numeric(df.get(\"vote_count\"), errors=\"coerce\"),\n",
    "        \"popularity\": pd.to_numeric(df.get(\"popularity\"), errors=\"coerce\"),\n",
    "        \"genres\": df.get(\"genres\").apply(parse_genres) if \"genres\" in df else [],\n",
    "        \"production_companies\": df.get(\"production_companies\").apply(\n",
    "            lambda xs: [x.get(\"name\") for x in xs] if isinstance(xs, list) else []\n",
    "        ) if \"production_companies\" in df else [],\n",
    "        \"production_countries\": df.get(\"production_countries\").apply(\n",
    "            lambda xs: [x.get(\"iso_3166_1\") for x in xs] if isinstance(xs, list) else []\n",
    "        ) if \"production_countries\" in df else [],\n",
    "    })\n",
    "    dt_series = pd.to_datetime(out[\"release_date\"], errors=\"coerce\")\n",
    "    out[\"release_year\"]  = dt_series.dt.year\n",
    "    out[\"release_month\"] = dt_series.dt.month\n",
    "    return out\n",
    "\n",
    "# ===================== 메인 =====================\n",
    "def main():\n",
    "    print(\"1) ID 수집 (🇰🇷 제작 ∩ 🇰🇷 극장 2|3)…\")\n",
    "    ids = collect_all_ids()\n",
    "    print(f\"   → 고유 ID 수: {len(ids):,}\")\n",
    "\n",
    "    print(\"2) 상세 수집 중…\")\n",
    "    rows = []\n",
    "    with tqdm(total=len(ids), desc=\"Fetch details\", leave=False) as bar:\n",
    "        for mid in ids:\n",
    "            d = fetch_detail(mid)\n",
    "            if d: rows.append(d)\n",
    "            bar.update(1)\n",
    "\n",
    "    print(\"3) 정규화 및 CSV 저장…\")\n",
    "    df = normalize_rows(rows)\n",
    "    df.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ 완료: {OUT_CSV} (rows={len(df):,})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e307625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 후보 로드: ./data_processed/kofic_candidates_kr_2005_2025.csv (rows=2,100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detail + domestic totals:   0%|          | 0/2100 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mkobis_get\u001b[39m\u001b[34m(path, params, retry)\u001b[39m\n\u001b[32m     61\u001b[39m     fi  = data[\u001b[33m\"\u001b[39m\u001b[33mfaultInfo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKOBIS fault: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi.get(\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (code=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi.get(\u001b[33m'\u001b[39m\u001b[33merrorCode\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mURL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m time.sleep(SLEEP)\n",
      "\u001b[31mRuntimeError\u001b[39m: KOBIS fault: 키의 하루 이용량을 초과하였습니다. (code=320011)\nURL: https://www.kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieInfo.json?key=e361a2a2bd988422e95115026e8a7850&movieCd=20050120",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 366\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(CANDIDATES_CSV):\n\u001b[32m    365\u001b[39m     build_candidates()\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[43menrich_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 329\u001b[39m, in \u001b[36menrich_and_save\u001b[39m\u001b[34m(candidates_csv, out_csv)\u001b[39m\n\u001b[32m    327\u001b[39m movieCd = \u001b[38;5;28mstr\u001b[39m(r[\u001b[33m\"\u001b[39m\u001b[33mmovieCd\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     info = \u001b[43mfetch_movie_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovieCd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    331\u001b[39m     bar.update(\u001b[32m1\u001b[39m); \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 278\u001b[39m, in \u001b[36mfetch_movie_info\u001b[39m\u001b[34m(movieCd)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch_movie_info\u001b[39m(movieCd: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     js = \u001b[43mkobis_get\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/movie/searchMovieInfo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmovieCd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovieCd\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m js.get(\u001b[33m\"\u001b[39m\u001b[33mmovieInfoResult\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\u001b[33m\"\u001b[39m\u001b[33mmovieInfo\u001b[39m\u001b[33m\"\u001b[39m, {}) \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mkobis_get\u001b[39m\u001b[34m(path, params, retry)\u001b[39m\n\u001b[32m     68\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m❌ Request failed:\u001b[39m\u001b[33m\"\u001b[39m, e, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mURL:\u001b[39m\u001b[33m\"\u001b[39m, url)\n\u001b[32m     69\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33munreachable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "2005-01-01 ~ 2025-12-31\n",
    "KOFIC(KOBIS)에서 '한국 제작 + 국내 극장 개봉' 영화만 후보 단계부터 선별하여\n",
    "TMDB 스타일 스키마 CSV 생성 (revenue=국내 최종 누적매출, audience_total=최종 누적관객)\n",
    "\n",
    "출력 열 순서:\n",
    "movie_id,title,original_title,original_language,release_date,runtime,budget,\n",
    "revenue,vote_average,vote_count,popularity,genres,production_companies,\n",
    "production_countries,release_year,release_month,audience_total\n",
    "\"\"\"\n",
    "\n",
    "import os, time, json, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "from urllib.parse import urlencode\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ===== 사용자 설정 =====\n",
    "START_DATE = \"2005-01-01\"\n",
    "END_DATE   = \"2025-12-31\"\n",
    "\n",
    "OUT_DIR        = \"./data_processed\"\n",
    "CANDIDATES_CSV = f\"{OUT_DIR}/kofic_candidates_kr_2005_2025.csv\"   # 한국만 담긴 후보\n",
    "OUT_CSV        = f\"{OUT_DIR}/kofic_domestic_kr_2005_2025.csv\"     # 최종 결과\n",
    "\n",
    "TIMEOUT = 20\n",
    "RETRY   = 3\n",
    "SLEEP   = 0.15  # 너무 낮추면 429 위험\n",
    "\n",
    "# 주간 박스오피스 기반 최종 누적 추정 파라미터\n",
    "JUMP_STEPS_DAYS     = [0, 14, 28, 56, 84]  # 개봉 후 0/2/4/8/12주\n",
    "LOCAL_REFINE_RADIUS = 7                    # 마지막 앵커 ±1주 보정\n",
    "MIN_ABS_DELTA  = 50_000_000               # 매출 증가 최소치(원)\n",
    "MIN_REL_DELTA  = 0.01                     # 증가율 임계(1%)\n",
    "PLATEAU_STREAK = 2                        # 2회 연속 정체 → 종료\n",
    "\n",
    "# ===== 준비 =====\n",
    "load_dotenv()\n",
    "KOFIC_KEY = os.getenv(\"KOFIC_API_KEY\") or os.getenv(\"KOBIS_KEY\")\n",
    "if not KOFIC_KEY:\n",
    "    raise SystemExit(\"❌ .env에 KOFIC_API_KEY(=KOBIS_KEY)가 없습니다.\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "BASE = \"https://www.kobis.or.kr/kobisopenapi/webservice/rest\"\n",
    "\n",
    "def kobis_get(path, params, retry=RETRY):\n",
    "    q = {\"key\": KOFIC_KEY, **params}\n",
    "    url = f\"{BASE}{path}.json?{urlencode(q)}\"\n",
    "    last_err = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=TIMEOUT)\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                time.sleep(min(2**i, 8)); continue\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if isinstance(data, dict) and data.get(\"faultInfo\"):\n",
    "                fi  = data[\"faultInfo\"]\n",
    "                raise RuntimeError(f\"KOBIS fault: {fi.get('message')} (code={fi.get('errorCode')})\\nURL: {url}\")\n",
    "            time.sleep(SLEEP)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            if i == retry - 1:\n",
    "                print(\"❌ Request failed:\", e, \"\\nURL:\", url)\n",
    "                raise\n",
    "            time.sleep(min(2**i, 8))\n",
    "    raise RuntimeError(f\"unreachable: {last_err}\")\n",
    "\n",
    "# ===== 공통 유틸 =====\n",
    "def to_iso_from_yyyymmdd(s):\n",
    "    if not s: return pd.NA\n",
    "    s = str(s)\n",
    "    if len(s) != 8 or not s.isdigit(): return pd.NA\n",
    "    return f\"{s[:4]}-{s[4:6]}-{s[6:]}\"\n",
    "\n",
    "def json_list_str(xs):\n",
    "    if xs is None: return \"[]\"\n",
    "    if isinstance(xs, list):\n",
    "        return json.dumps(xs, ensure_ascii=False)\n",
    "    return json.dumps([str(xs)], ensure_ascii=False)\n",
    "\n",
    "def sunday_of_week(d: date) -> date:\n",
    "    # 월=0..일=6 → 일요일로 보정\n",
    "    return d + timedelta(days=(6 - d.weekday()))\n",
    "\n",
    "def is_korean_production(info):\n",
    "    nations = [n.get(\"nationNm\") for n in (info.get(\"nations\") or []) if n.get(\"nationNm\")]\n",
    "    return any(str(n).strip() in {\"한국\",\"대한민국\",\"Korea\",\"South Korea\",\"Republic of Korea\"} for n in nations)\n",
    "\n",
    "def in_period_open(info, start=START_DATE, end=END_DATE):\n",
    "    openDt = info.get(\"openDt\")\n",
    "    if not openDt: return False\n",
    "    iso = to_iso_from_yyyymmdd(openDt)\n",
    "    if pd.isna(iso): return False\n",
    "    return (iso >= start) and (iso <= end)\n",
    "\n",
    "# ===== (옵션2) 공통코드에서 ‘한국’ 8자리 코드 조회 =====\n",
    "# 에러 메시지에 ‘공통코드220310’이 언급되는 경우가 있어 다양한 후보 comCode를 순회 탐색\n",
    "CODE_TABLE_CANDIDATES = [\"220310\", \"2204\", \"22003\", \"2203\", \"220301\", \"220201\"]\n",
    "\n",
    "def get_korea_code(verbose=True):\n",
    "    for cc in CODE_TABLE_CANDIDATES:\n",
    "        try:\n",
    "            js = kobis_get(\"/code/searchCodeList\", {\"comCode\": cc})\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  · 공통코드 {cc} 조회 실패: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 응답 구조 가변 대응\n",
    "        code_list = (\n",
    "            (js.get(\"codeListResult\") or {}).get(\"codeList\")\n",
    "            or js.get(\"codes\")\n",
    "            or js.get(\"codeList\")\n",
    "            or []\n",
    "        )\n",
    "\n",
    "        found = None\n",
    "        for c in code_list:\n",
    "            name_ko = c.get(\"korNm\") or c.get(\"codeNm\") or c.get(\"korName\") or \"\"\n",
    "            name_en = (c.get(\"engNm\") or c.get(\"engName\") or \"\").upper()\n",
    "            code    = c.get(\"fullCd\") or c.get(\"code\") or c.get(\"cd\") or \"\"\n",
    "            if ((\"한국\" in name_ko) or (\"대한민국\" in name_ko)\n",
    "                or (\"KOREA\" in name_en) or (\"REPUBLIC OF KOREA\" in name_en)):\n",
    "                if isinstance(code, str) and len(code) == 8 and code.isdigit():\n",
    "                    found = code; break\n",
    "\n",
    "        if found:\n",
    "            if verbose:\n",
    "                print(f\"✅ 한국 코드 발견 (comCode={cc}): {found}\")\n",
    "            return found\n",
    "\n",
    "    if verbose:\n",
    "        print(\"⚠️ 공통코드 테이블에서 한국 코드(8자리)를 찾지 못했습니다. 응답 필터 폴백을 사용합니다.\")\n",
    "    return None\n",
    "\n",
    "# ===== 1) 후보(연도별) 수집: ‘서버 필터(한국)’ 우선, 실패시 폴백(응답에서 한국만 선별) =====\n",
    "KR_LABELS = {\"한국\",\"대한민국\",\"Korea\",\"South Korea\",\"Republic of Korea\"}\n",
    "\n",
    "def find_candidates_by_year(year: int, kr_code: str | None):\n",
    "    y = str(year)\n",
    "    # 우선 ‘연/기간’ 3가지 패턴으로 프로브 → 성공 조합으로 페이징\n",
    "    base_patterns = [\n",
    "        {\"openStartDt\": y,          \"openEndDt\": y          },\n",
    "        {\"openStartDt\": y                                  },\n",
    "        {\"openStartDt\": f\"{y}0101\", \"openEndDt\": f\"{y}1231\"},\n",
    "    ]\n",
    "\n",
    "    def probe(params):\n",
    "        js = kobis_get(\"/movie/searchMovieList\", {**params, \"itemPerPage\": 10, \"curPage\": 1})\n",
    "        res = js.get(\"movieListResult\", {}) or {}\n",
    "        tot = res.get(\"totCnt\")\n",
    "        return int(tot) if (isinstance(tot, (int,str)) and str(tot).isdigit()) else 0\n",
    "\n",
    "    chosen = None\n",
    "    mode = \"ANY\"\n",
    "\n",
    "    # 1) repNationCd=한국코드 사용 프로브\n",
    "    if kr_code:\n",
    "        for p in base_patterns:\n",
    "            params = {**p, \"repNationCd\": kr_code}\n",
    "            if probe(params) > 0:\n",
    "                chosen = params\n",
    "                mode = \"KCODE\"\n",
    "                break\n",
    "\n",
    "    # 2) 실패 시 무필터로 프로브\n",
    "    if chosen is None:\n",
    "        for p in base_patterns:\n",
    "            if probe(p) > 0:\n",
    "                chosen = p\n",
    "                mode = \"ANY\"\n",
    "                break\n",
    "\n",
    "    if chosen is None:\n",
    "        print(f\"  · {year}: 후보 0건 (건너뜀)\")\n",
    "        return []\n",
    "\n",
    "    out, per_page, cur_page, total_seen = [], 100, 1, None\n",
    "    while True:\n",
    "        params = {**chosen, \"itemPerPage\": per_page, \"curPage\": cur_page}\n",
    "        js = kobis_get(\"/movie/searchMovieList\", params)\n",
    "        res = js.get(\"movieListResult\", {}) or {}\n",
    "        lst = res.get(\"movieList\", []) or []\n",
    "        tot = res.get(\"totCnt\", None)\n",
    "        if total_seen is None and tot is not None:\n",
    "            total_seen = int(tot)\n",
    "\n",
    "        if not lst: break\n",
    "\n",
    "        for x in lst:\n",
    "            mc  = x.get(\"movieCd\")\n",
    "            rep = (x.get(\"repNationNm\") or \"\").strip()\n",
    "            if not mc:\n",
    "                continue\n",
    "            if (mode == \"KCODE\") or (rep in KR_LABELS):\n",
    "                out.append((mc, x.get(\"movieNm\"), x.get(\"openDt\")))\n",
    "\n",
    "        # repNationCd를 쓴 경우에는 totCnt에 신뢰\n",
    "        if (mode == \"KCODE\") and (total_seen is not None) and (len(out) >= total_seen):\n",
    "            break\n",
    "\n",
    "        cur_page += 1\n",
    "        time.sleep(SLEEP)\n",
    "\n",
    "    print(f\"  · {year}: mode={mode:<6}, collected(K-only)={len(out):>5}\")\n",
    "    return out\n",
    "\n",
    "def build_candidates(save_path=CANDIDATES_CSV, start=START_DATE, end=END_DATE):\n",
    "    s_year, e_year = int(start[:4]), int(end[:4])\n",
    "    print(\"연도별 후보 수집(서버 한국코드 우선)…\")\n",
    "    kr_code = get_korea_code(verbose=True)\n",
    "    cands = []\n",
    "    for y in range(s_year, e_year+1):\n",
    "        cands.extend(find_candidates_by_year(y, kr_code))\n",
    "    df = pd.DataFrame(cands, columns=[\"movieCd\",\"movieNm\",\"openDt\"]).drop_duplicates(\"movieCd\")\n",
    "    df.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"📄 후보 저장(한국만): {save_path} (고유 {len(df):,}편)\")\n",
    "    return df\n",
    "\n",
    "# ===== 2) 주간 박스오피스 기반 누적(매출/관객) 추정 =====\n",
    "weekly_cache = {}\n",
    "\n",
    "def weekly_items(target_yyyymmdd: str):\n",
    "    if target_yyyymmdd in weekly_cache:\n",
    "        return weekly_cache[target_yyyymmdd]\n",
    "    js = kobis_get(\"/boxoffice/searchWeeklyBoxOfficeList\",\n",
    "                   {\"targetDt\": target_yyyymmdd, \"weekGb\": \"0\"})\n",
    "    items = js.get(\"boxOfficeResult\", {}).get(\"weeklyBoxOfficeList\", []) or []\n",
    "    weekly_cache[target_yyyymmdd] = items\n",
    "    return items\n",
    "\n",
    "def get_acc_from_weekly_by_code(movieCd: str, target_date: date):\n",
    "    tgt = sunday_of_week(target_date).strftime(\"%Y%m%d\")\n",
    "    for it in weekly_items(tgt):\n",
    "        if it.get(\"movieCd\") == movieCd:\n",
    "            s = pd.to_numeric(it.get(\"salesAcc\"), errors=\"coerce\") or 0\n",
    "            a = pd.to_numeric(it.get(\"audiAcc\"),  errors=\"coerce\") or 0\n",
    "            return s, a\n",
    "    return 0, 0\n",
    "\n",
    "def intelligent_final_acc(movieCd: str, open_yyyymmdd: str):\n",
    "    if not open_yyyymmdd or len(str(open_yyyymmdd)) != 8:\n",
    "        return (pd.NA, pd.NA)\n",
    "    base = datetime.strptime(open_yyyymmdd, \"%Y%m%d\").date()\n",
    "\n",
    "    best_sales, best_audi = 0.0, 0.0\n",
    "    plateau_cnt, prev = 0, 0.0\n",
    "\n",
    "    for dd in JUMP_STEPS_DAYS:\n",
    "        anchor = base + timedelta(days=dd)\n",
    "        s, a = get_acc_from_weekly_by_code(movieCd, anchor)\n",
    "        if s > best_sales: best_sales = s\n",
    "        if a > best_audi:  best_audi  = a\n",
    "\n",
    "        delta = best_sales - prev\n",
    "        rel = (delta/prev) if prev > 0 else 1.0\n",
    "        plateau_cnt = plateau_cnt + 1 if (delta < MIN_ABS_DELTA and rel < MIN_REL_DELTA) else 0\n",
    "        prev = best_sales\n",
    "\n",
    "        if plateau_cnt >= PLATEAU_STREAK:\n",
    "            for d in range(-LOCAL_REFINE_RADIUS, LOCAL_REFINE_RADIUS+1, 7):\n",
    "                anchor2 = anchor + timedelta(days=d)\n",
    "                s2, a2 = get_acc_from_weekly_by_code(movieCd, anchor2)\n",
    "                if s2 > best_sales: best_sales = s2\n",
    "                if a2 > best_audi:  best_audi  = a2\n",
    "            break\n",
    "\n",
    "    return (pd.NA if best_sales == 0 else best_sales,\n",
    "            pd.NA if best_audi  == 0 else best_audi)\n",
    "\n",
    "# ===== 3) 상세 → TMDB 스타일 행 빌드 =====\n",
    "def fetch_movie_info(movieCd: str):\n",
    "    js = kobis_get(\"/movie/searchMovieInfo\", {\"movieCd\": movieCd})\n",
    "    return js.get(\"movieInfoResult\", {}).get(\"movieInfo\", {}) or {}\n",
    "\n",
    "def to_tmdb_row(info, salesAcc_final, audiAcc_final):\n",
    "    movieCd   = info.get(\"movieCd\")\n",
    "    movieNm   = info.get(\"movieNm\")\n",
    "    movieNmEn = info.get(\"movieNmEn\") or movieNm\n",
    "    openDt    = info.get(\"openDt\")  # yyyymmdd\n",
    "    release_date = to_iso_from_yyyymmdd(openDt)\n",
    "\n",
    "    dt = pd.to_datetime(release_date, errors=\"coerce\") if pd.notna(release_date) else pd.NaT\n",
    "    release_year  = (dt.year  if pd.notna(dt) else pd.NA)\n",
    "    release_month = (dt.month if pd.notna(dt) else pd.NA)\n",
    "\n",
    "    showTm = pd.to_numeric(info.get(\"showTm\"), errors=\"coerce\")\n",
    "    genres    = [g.get(\"genreNm\")   for g in (info.get(\"genres\")   or []) if g.get(\"genreNm\")]\n",
    "    companies = [c.get(\"companyNm\") for c in (info.get(\"companys\") or []) if c.get(\"companyNm\")]\n",
    "\n",
    "    return {\n",
    "        \"movie_id\": movieCd,\n",
    "        \"title\": movieNm,\n",
    "        \"original_title\": movieNmEn,\n",
    "        \"original_language\": \"ko\",\n",
    "        \"release_date\": release_date,\n",
    "        \"runtime\": showTm,\n",
    "        \"budget\": pd.NA,\n",
    "        \"revenue\": pd.to_numeric(salesAcc_final),  # 국내 최종 누적매출(원)\n",
    "        \"vote_average\": pd.NA,\n",
    "        \"vote_count\": pd.NA,\n",
    "        \"popularity\": pd.NA,\n",
    "        \"genres\": json_list_str(genres),\n",
    "        \"production_companies\": json_list_str(companies),\n",
    "        \"production_countries\": json_list_str([\"KR\"]),\n",
    "        \"release_year\": release_year,\n",
    "        \"release_month\": release_month,\n",
    "        \"audience_total\": pd.to_numeric(audiAcc_final),  # 국내 최종 누적관객\n",
    "    }\n",
    "\n",
    "def enrich_and_save(candidates_csv=CANDIDATES_CSV, out_csv=OUT_CSV):\n",
    "    # 후보 로드 or 생성\n",
    "    if os.path.exists(candidates_csv):\n",
    "        cand = pd.read_csv(candidates_csv, dtype=str)\n",
    "        print(f\"📄 후보 로드: {candidates_csv} (rows={len(cand):,})\")\n",
    "    else:\n",
    "        cand = build_candidates()\n",
    "\n",
    "    rows = []\n",
    "    with tqdm(total=len(cand), desc=\"Detail + domestic totals\") as bar:\n",
    "        for _, r in cand.iterrows():\n",
    "            movieCd = str(r[\"movieCd\"])\n",
    "            try:\n",
    "                info = fetch_movie_info(movieCd)\n",
    "            except Exception:\n",
    "                bar.update(1); continue\n",
    "\n",
    "            # 상세에서도 한국 제작 & 기간 내 개봉 확인 (이중 안전망)\n",
    "            if (not is_korean_production(info)) or (not in_period_open(info)):\n",
    "                bar.update(1); continue\n",
    "\n",
    "            try:\n",
    "                s_final, a_final = intelligent_final_acc(movieCd, info.get(\"openDt\"))\n",
    "            except Exception:\n",
    "                s_final, a_final = (pd.NA, pd.NA)\n",
    "\n",
    "            rows.append(to_tmdb_row(info, s_final, a_final))\n",
    "            bar.update(1)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df[\"runtime\"]        = pd.to_numeric(df[\"runtime\"], errors=\"coerce\")\n",
    "        df[\"revenue\"]        = pd.to_numeric(df[\"revenue\"], errors=\"coerce\")\n",
    "        df[\"audience_total\"] = pd.to_numeric(df[\"audience_total\"], errors=\"coerce\")\n",
    "        df[\"release_year\"]   = pd.to_numeric(df[\"release_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        df[\"release_month\"]  = pd.to_numeric(df[\"release_month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    cols = [\"movie_id\",\"title\",\"original_title\",\"original_language\",\"release_date\",\"runtime\",\"budget\",\n",
    "            \"revenue\",\"vote_average\",\"vote_count\",\"popularity\",\"genres\",\"production_companies\",\n",
    "            \"production_countries\",\"release_year\",\"release_month\",\"audience_total\"]\n",
    "    df = df.reindex(columns=cols)\n",
    "\n",
    "    df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ 저장 완료: {out_csv} (rows={len(df):,})\")\n",
    "    print(f\"🗃 weekly_cache 크기(앵커 호출 수): {len(weekly_cache):,}\")\n",
    "\n",
    "# ===== 실행 =====\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(CANDIDATES_CSV):\n",
    "        build_candidates()\n",
    "    enrich_and_save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59434400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kofic_resume_from_candidates.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, time, json, requests, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "from urllib.parse import urlencode\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ========= 설정 =========\n",
    "CANDIDATES_CSV = \"./data_processed/kofic_candidates_kr_2005_2025.csv\"   # 이미 확보한 후보 목록\n",
    "OUT_PARTIAL    = \"./data_processed/kofic_domestic_partial.csv\"          # 실행할 때마다 이어붙임\n",
    "DONE_IDS_TXT   = \"./data_processed/kofic_done_ids.txt\"                  # 처리 완료 id 기록\n",
    "OUT_FINAL      = \"./data_processed/kofic_domestic_final.csv\"            # 최종 머지본 (원하는 시점에 생성)\n",
    "\n",
    "TIMEOUT = 20\n",
    "RETRY   = 3\n",
    "SLEEP   = 0.15\n",
    "\n",
    "# 요청 예산(대략): 영화 1편당 ~6~12회 호출(정보 1 + 주간 5~10)\n",
    "# 오늘 남은 호출을 넉넉히 보수적으로 잡아 MOVIES_PER_RUN 만큼만 처리\n",
    "MOVIES_PER_RUN = 120  # 한 번 실행에 처리할 최대 영화 개수 (상황에 맞게 조절)\n",
    "\n",
    "# 주간 박스오피스 점프 앵커(개봉 후 경과일)\n",
    "JUMP_STEPS_DAYS     = [0, 14, 28, 56]  # 필요하면 84 추가\n",
    "LOCAL_REFINE_RADIUS = 7\n",
    "MIN_ABS_DELTA  = 50_000_000  # 원 단위 최소 증가량\n",
    "MIN_REL_DELTA  = 0.01        # 1%\n",
    "PLATEAU_STREAK = 2\n",
    "\n",
    "load_dotenv()\n",
    "KOFIC_KEY = os.getenv(\"KOFIC_API_KEY\") or os.getenv(\"KOBIS_KEY\")\n",
    "BASE = \"https://www.kobis.or.kr/kobisopenapi/webservice/rest\"\n",
    "os.makedirs(os.path.dirname(OUT_PARTIAL), exist_ok=True)\n",
    "\n",
    "def kobis_get(path, params, retry=RETRY):\n",
    "    q = {\"key\": KOFIC_KEY, **params}\n",
    "    url = f\"{BASE}{path}.json?{urlencode(q)}\"\n",
    "    last = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=TIMEOUT)\n",
    "            if r.status_code in (429,500,502,503,504):\n",
    "                time.sleep(min(2**i,8)); continue\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if data.get(\"faultInfo\"):\n",
    "                fi = data[\"faultInfo\"]\n",
    "                raise RuntimeError(f\"KOBIS fault: {fi.get('message')} (code={fi.get('errorCode')})\")\n",
    "            time.sleep(SLEEP)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            if i == retry-1: raise\n",
    "            time.sleep(min(2**i,8))\n",
    "    raise RuntimeError(last)\n",
    "\n",
    "def sunday_of_week(d: date) -> date:\n",
    "    return d + timedelta(days=(6 - d.weekday()))\n",
    "\n",
    "def weekly_items(target_yyyymmdd: str, cache: dict):\n",
    "    if target_yyyymmdd in cache:\n",
    "        return cache[target_yyyymmdd]\n",
    "    js = kobis_get(\"/boxoffice/searchWeeklyBoxOfficeList\", {\"targetDt\": target_yyyymmdd, \"weekGb\":\"0\"})\n",
    "    items = js.get(\"boxOfficeResult\", {}).get(\"weeklyBoxOfficeList\", []) or []\n",
    "    cache[target_yyyymmdd] = items\n",
    "    return items\n",
    "\n",
    "def get_acc_from_weekly_by_code(movieCd: str, anchor_date: date, cache: dict):\n",
    "    tgt = sunday_of_week(anchor_date).strftime(\"%Y%m%d\")\n",
    "    for it in weekly_items(tgt, cache):\n",
    "        if it.get(\"movieCd\") == movieCd:\n",
    "            s = pd.to_numeric(it.get(\"salesAcc\"), errors=\"coerce\") or 0\n",
    "            a = pd.to_numeric(it.get(\"audiAcc\"),  errors=\"coerce\") or 0\n",
    "            return s, a\n",
    "    return 0, 0\n",
    "\n",
    "def intelligent_final_acc(movieCd: str, open_yyyymmdd: str, cache: dict):\n",
    "    if not open_yyyymmdd or len(str(open_yyyymmdd))!=8:\n",
    "        return (pd.NA, pd.NA)\n",
    "    base = datetime.strptime(open_yyyymmdd, \"%Y%m%d\").date()\n",
    "\n",
    "    best_sales, best_audi = 0.0, 0.0\n",
    "    plateau_cnt, prev = 0, 0.0\n",
    "\n",
    "    for dd in JUMP_STEPS_DAYS:\n",
    "        anchor = base + timedelta(days=dd)\n",
    "        s, a = get_acc_from_weekly_by_code(movieCd, anchor, cache)\n",
    "        if s > best_sales: best_sales = s\n",
    "        if a > best_audi:  best_audi  = a\n",
    "\n",
    "        delta = best_sales - prev\n",
    "        rel = (delta/prev) if prev>0 else 1.0\n",
    "        plateau_cnt = plateau_cnt + 1 if (delta < MIN_ABS_DELTA and rel < MIN_REL_DELTA) else 0\n",
    "        prev = best_sales\n",
    "\n",
    "        if plateau_cnt >= PLATEAU_STREAK:\n",
    "            for d in range(-LOCAL_REFINE_RADIUS, LOCAL_REFINE_RADIUS+1, 7):\n",
    "                anchor2 = anchor + timedelta(days=d)\n",
    "                s2, a2 = get_acc_from_weekly_by_code(movieCd, anchor2, cache)\n",
    "                if s2 > best_sales: best_sales = s2\n",
    "                if a2 > best_audi:  best_audi  = a2\n",
    "            break\n",
    "\n",
    "    return (pd.NA if best_sales==0 else best_sales,\n",
    "            pd.NA if best_audi==0  else best_audi)\n",
    "\n",
    "def to_iso_from_yyyymmdd(s):\n",
    "    if not s: return pd.NA\n",
    "    s=str(s)\n",
    "    return f\"{s[:4]}-{s[4:6]}-{s[6:]}\" if len(s)>=8 else pd.NA\n",
    "\n",
    "def json_list_str(xs):\n",
    "    if xs is None: return \"[]\"\n",
    "    if isinstance(xs, list): return json.dumps(xs, ensure_ascii=False)\n",
    "    return json.dumps([str(xs)], ensure_ascii=False)\n",
    "\n",
    "def fetch_movie_info(movieCd: str):\n",
    "    js = kobis_get(\"/movie/searchMovieInfo\", {\"movieCd\": movieCd})\n",
    "    return js.get(\"movieInfoResult\", {}).get(\"movieInfo\", {}) or {}\n",
    "\n",
    "def to_tmdb_row(info, salesAcc_final, audiAcc_final):\n",
    "    movieCd   = info.get(\"movieCd\")\n",
    "    movieNm   = info.get(\"movieNm\")\n",
    "    movieNmEn = info.get(\"movieNmEn\") or movieNm\n",
    "    openDt    = info.get(\"openDt\")  # yyyymmdd\n",
    "    iso       = to_iso_from_yyyymmdd(openDt)\n",
    "    dt        = pd.to_datetime(iso, errors=\"coerce\") if pd.notna(iso) else pd.NaT\n",
    "    release_year  = (dt.year  if pd.notna(dt) else pd.NA)\n",
    "    release_month = (dt.month if pd.notna(dt) else pd.NA)\n",
    "    showTm = pd.to_numeric(info.get(\"showTm\"), errors=\"coerce\")\n",
    "\n",
    "    genres    = [g.get(\"genreNm\")   for g in (info.get(\"genres\")   or []) if g.get(\"genreNm\")]\n",
    "    companies = [c.get(\"companyNm\") for c in (info.get(\"companys\") or []) if c.get(\"companyNm\")]\n",
    "\n",
    "    return {\n",
    "        \"movie_id\": movieCd,\n",
    "        \"title\": movieNm,\n",
    "        \"original_title\": movieNmEn,\n",
    "        \"original_language\": \"ko\",\n",
    "        \"release_date\": iso,\n",
    "        \"runtime\": showTm,\n",
    "        \"budget\": pd.NA,\n",
    "        \"revenue\": pd.to_numeric(salesAcc_final),\n",
    "        \"vote_average\": pd.NA,\n",
    "        \"vote_count\": pd.NA,\n",
    "        \"popularity\": pd.NA,\n",
    "        \"genres\": json_list_str(genres),\n",
    "        \"production_companies\": json_list_str(companies),\n",
    "        \"production_countries\": json_list_str([\"KR\"]),\n",
    "        \"release_year\": release_year,\n",
    "        \"release_month\": release_month,\n",
    "        \"audience_total\": pd.to_numeric(audiAcc_final),\n",
    "    }\n",
    "\n",
    "def load_done_ids():\n",
    "    if not os.path.exists(DONE_IDS_TXT):\n",
    "        return set()\n",
    "    with open(DONE_IDS_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "        return set(line.strip() for line in f if line.strip())\n",
    "\n",
    "def append_done_id(mid: str):\n",
    "    with open(DONE_IDS_TXT, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(mid+\"\\n\")\n",
    "\n",
    "def append_partial_row(row: dict):\n",
    "    df = pd.DataFrame([row])\n",
    "    header = not os.path.exists(OUT_PARTIAL)\n",
    "    df.to_csv(OUT_PARTIAL, index=False, mode=(\"w\" if header else \"a\"),\n",
    "              header=header, encoding=\"utf-8-sig\")\n",
    "\n",
    "def main():\n",
    "    if not KOFIC_KEY:\n",
    "        raise SystemExit(\"❌ .env에 KOFIC_API_KEY(=KOBIS_KEY)가 없습니다.\")\n",
    "\n",
    "    cand = pd.read_csv(CANDIDATES_CSV, dtype=str)\n",
    "    done = load_done_ids()\n",
    "\n",
    "    # 처리 대상 = 아직 안 한 movieCd\n",
    "    todo = [mc for mc in cand[\"movieCd\"].astype(str).unique() if mc not in done]\n",
    "    if not todo:\n",
    "        print(\"모든 후보가 처리되었습니다.\")\n",
    "        return\n",
    "\n",
    "    # 오늘 실행에 처리할 배치\n",
    "    batch = todo[:MOVIES_PER_RUN]\n",
    "    print(f\"이번 배치 처리 예정: {len(batch)}편  (남은 후보 {len(todo)-len(batch)}편)\")\n",
    "\n",
    "    cache = {}\n",
    "    with tqdm(total=len(batch), desc=\"Collect\") as bar:\n",
    "        for movieCd in batch:\n",
    "            try:\n",
    "                info = fetch_movie_info(movieCd)\n",
    "            except Exception as e:\n",
    "                print(\"info 실패:\", movieCd, e); bar.update(1); continue\n",
    "\n",
    "            # 한국 국가/개봉일 기본 검증 (안전망)\n",
    "            nations = [n.get(\"nationNm\") for n in (info.get(\"nations\") or [])]\n",
    "            if not any(str(n).strip() in {\"한국\",\"대한민국\",\"Korea\",\"South Korea\",\"Republic of Korea\"} for n in nations):\n",
    "                bar.update(1); append_done_id(movieCd); continue\n",
    "\n",
    "            try:\n",
    "                s_final, a_final = intelligent_final_acc(movieCd, info.get(\"openDt\"), cache)\n",
    "            except Exception as e:\n",
    "                print(\"weekly 실패:\", movieCd, e)\n",
    "                s_final, a_final = (pd.NA, pd.NA)\n",
    "\n",
    "            row = to_tmdb_row(info, s_final, a_final)\n",
    "            append_partial_row(row)\n",
    "            append_done_id(movieCd)\n",
    "            bar.update(1)\n",
    "\n",
    "    # 원할 때 최종 CSV로 재정렬/머지\n",
    "    cols = [\"movie_id\",\"title\",\"original_title\",\"original_language\",\"release_date\",\"runtime\",\"budget\",\n",
    "            \"revenue\",\"vote_average\",\"vote_count\",\"popularity\",\"genres\",\"production_companies\",\n",
    "            \"production_countries\",\"release_year\",\"release_month\",\"audience_total\"]\n",
    "\n",
    "    part = pd.read_csv(OUT_PARTIAL, dtype=str)\n",
    "    # 타입/정렬 보정\n",
    "    part[\"release_year\"]  = pd.to_numeric(part[\"release_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    part[\"release_month\"] = pd.to_numeric(part[\"release_month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    part[\"runtime\"]       = pd.to_numeric(part[\"runtime\"], errors=\"coerce\")\n",
    "    part[\"revenue\"]       = pd.to_numeric(part[\"revenue\"], errors=\"coerce\")\n",
    "    part[\"audience_total\"]= pd.to_numeric(part[\"audience_total\"], errors=\"coerce\")\n",
    "    part = part.drop_duplicates(subset=[\"movie_id\"]).sort_values([\"release_year\",\"release_month\",\"title\"])\n",
    "    part.reindex(columns=cols).to_csv(OUT_FINAL, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ 최종 병합 저장: {OUT_FINAL} (rows={len(part):,})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b7a1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이번 배치: 800편 / 남은 2251편\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "movieInfo + merge (KR only):   0%|          | 1/800 [00:03<42:44,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip 20040756 KOBIS fault: 유효하지않은 키값입니다. (code=320010)\n",
      "URL: https://www.kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieInfo.json?key=%2283eff9d2cad944234ee5924c9e498a61%22+%23+%EB%8F%84%EB%AF%BC+2&movieCd=20040756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "movieInfo + merge (KR only):   0%|          | 1/800 [00:06<1:24:34,  6.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mkobis_get\u001b[39m\u001b[34m(path, params, retry)\u001b[39m\n\u001b[32m     59\u001b[39m     fi = data[\u001b[33m\"\u001b[39m\u001b[33mfaultInfo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKOBIS fault: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi.get(\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (code=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi.get(\u001b[33m'\u001b[39m\u001b[33merrorCode\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mURL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m time.sleep(SLEEP)\n",
      "\u001b[31mRuntimeError\u001b[39m: KOBIS fault: 유효하지않은 키값입니다. (code=320010)\nURL: https://www.kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieInfo.json?key=%2283eff9d2cad944234ee5924c9e498a61%22+%23+%EB%8F%84%EB%AF%BC+2&movieCd=20040706",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 228\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ 저장: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUT_FINAL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (rows=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(part)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 186\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cd \u001b[38;5;129;01min\u001b[39;00m tqdm(batch, desc=\u001b[33m\"\u001b[39m\u001b[33mmovieInfo + merge (KR only)\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         info = \u001b[43mfetch_movie_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m         \u001b[38;5;66;03m# 한국 제작 필터 + 개봉일(기간 내 안전망)\u001b[39;00m\n\u001b[32m    188\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_korean_production(info):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 117\u001b[39m, in \u001b[36mfetch_movie_info\u001b[39m\u001b[34m(cd)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch_movie_info\u001b[39m(cd: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     js = \u001b[43mkobis_get\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/movie/searchMovieInfo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmovieCd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcd\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m js.get(\u001b[33m\"\u001b[39m\u001b[33mmovieInfoResult\u001b[39m\u001b[33m\"\u001b[39m,{}).get(\u001b[33m\"\u001b[39m\u001b[33mmovieInfo\u001b[39m\u001b[33m\"\u001b[39m,{}) \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mkobis_get\u001b[39m\u001b[34m(path, params, retry)\u001b[39m\n\u001b[32m     64\u001b[39m         last = e\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m i == retry-\u001b[32m1\u001b[39m: \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(last)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# kobis_weekly_to_tmdb_csv.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "2005-01-01 ~ 2025-12-31\n",
    "KOBIS(=KOFIC OpenAPI)에서 '주간 박스오피스 Top10에 한 번이라도 등장'한 영화만 선별\n",
    "→ 한국 제작만 필터 → TMDB 스타일 스키마 CSV 생성\n",
    "(revenue = 국내 최종 누적매출, audience_total = 국내 최종 누적관객)\n",
    "\n",
    "출력 열 순서:\n",
    "movie_id,title,original_title,original_language,release_date,runtime,budget,\n",
    "revenue,vote_average,vote_count,popularity,genres,production_companies,\n",
    "production_countries,release_year,release_month,audience_total\n",
    "\"\"\"\n",
    "\n",
    "import os, time, json, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime, timedelta\n",
    "from urllib.parse import urlencode\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ========= 기간/경로 설정 =========\n",
    "START = date(2005, 1, 1)\n",
    "END   = date(2025,12,31)\n",
    "\n",
    "OUT_DIR       = \"./data_processed\"\n",
    "WEEKLY_PICKLE = f\"{OUT_DIR}/kobis_weekly_pool.pkl\"      # 주간 스캔 결과 캐시\n",
    "OUT_PARTIAL   = f\"{OUT_DIR}/kobis_weekly_partial.csv\"   # 메타 누적(재시작용)\n",
    "OUT_FINAL     = f\"{OUT_DIR}/kobis_weekly_final.csv\"     # 최종 TMDB형\n",
    "\n",
    "# 하루에 처리할 movieInfo 개수(쿼터 따라 조정)\n",
    "MOVIES_PER_RUN = 800\n",
    "\n",
    "# 요청/재시도\n",
    "TIMEOUT = 20\n",
    "RETRY   = 3\n",
    "SLEEP   = 0.12\n",
    "\n",
    "# ========= 인증 =========\n",
    "load_dotenv()\n",
    "KOBIS_KEY = os.getenv(\"KOFIC_API_KEY\") or os.getenv(\"KOBIS_KEY\")\n",
    "BASE = \"https://www.kobis.or.kr/kobisopenapi/webservice/rest\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ========= 공통 HTTP =========\n",
    "def kobis_get(path, params, retry=RETRY):\n",
    "    q = {\"key\": KOBIS_KEY, **params}\n",
    "    url = f\"{BASE}{path}.json?{urlencode(q)}\"\n",
    "    last = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=TIMEOUT)\n",
    "            if r.status_code in (429,500,502,503,504):\n",
    "                time.sleep(min(2**i,8)); continue\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if data.get(\"faultInfo\"):\n",
    "                fi = data[\"faultInfo\"]\n",
    "                raise RuntimeError(f\"KOBIS fault: {fi.get('message')} (code={fi.get('errorCode')})\\nURL: {url}\")\n",
    "            time.sleep(SLEEP)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            if i == retry-1: raise\n",
    "            time.sleep(min(2**i,8))\n",
    "    raise RuntimeError(last)\n",
    "\n",
    "# ========= 유틸 =========\n",
    "def sundays(start: date, end: date):\n",
    "    # start 기준 그 주 일요일(weekGb=0 사용)\n",
    "    s = start + timedelta(days=(6 - start.weekday()))\n",
    "    while s <= end:\n",
    "        yield s\n",
    "        s += timedelta(days=7)\n",
    "\n",
    "def to_iso_from_yyyymmdd(s):\n",
    "    if not s: return pd.NA\n",
    "    s = str(s)\n",
    "    return f\"{s[:4]}-{s[4:6]}-{s[6:]}\" if len(s) >= 8 else pd.NA\n",
    "\n",
    "def json_list_str(xs):\n",
    "    if xs is None: return \"[]\"\n",
    "    if isinstance(xs, list): return json.dumps(xs, ensure_ascii=False)\n",
    "    return json.dumps([str(xs)], ensure_ascii=False)\n",
    "\n",
    "# ========= 1) 주간 Top10 스캔: 등장 영화 + 최종 누적 =========\n",
    "def weekly_scan():\n",
    "    \"\"\"\n",
    "    주간 박스오피스(Top10) 전체 주차 스캔 → movieCd별 최댓값 누적매출/관객 및 기본 정보 모음\n",
    "    반환: dict[movieCd] = {max_sales, max_audi, movieNm, openDt, weeks}\n",
    "    \"\"\"\n",
    "    pool = {}  # movieCd -> dict\n",
    "    for s in tqdm(list(sundays(START, END)), desc=\"Weekly scan (Top10)\"):\n",
    "        js = kobis_get(\"/boxoffice/searchWeeklyBoxOfficeList\",\n",
    "                       {\"targetDt\": s.strftime(\"%Y%m%d\"), \"weekGb\": \"0\"})\n",
    "        items = js.get(\"boxOfficeResult\",{}).get(\"weeklyBoxOfficeList\",[]) or []\n",
    "        for it in items:\n",
    "            cd  = it.get(\"movieCd\")\n",
    "            if not cd: continue\n",
    "            nm  = it.get(\"movieNm\")\n",
    "            odt = it.get(\"openDt\")  # yyyymmdd\n",
    "            salesAcc = pd.to_numeric(it.get(\"salesAcc\"), errors=\"coerce\") or 0\n",
    "            audiAcc  = pd.to_numeric(it.get(\"audiAcc\"),  errors=\"coerce\") or 0\n",
    "            rec = pool.get(cd, {\"max_sales\":0, \"max_audi\":0, \"movieNm\":nm, \"openDt\":odt, \"weeks\":0})\n",
    "            rec[\"max_sales\"] = max(rec[\"max_sales\"], salesAcc)\n",
    "            rec[\"max_audi\"]  = max(rec[\"max_audi\"],  audiAcc)\n",
    "            rec[\"weeks\"]     = rec[\"weeks\"] + 1\n",
    "            if not rec.get(\"movieNm\"):  rec[\"movieNm\"] = nm\n",
    "            if not rec.get(\"openDt\"):   rec[\"openDt\"]  = odt\n",
    "            pool[cd] = rec\n",
    "    pd.to_pickle(pool, WEEKLY_PICKLE)\n",
    "    return pool\n",
    "\n",
    "# ========= 2) movieInfo 메타(한국 제작 필터) + TMDB 스키마로 변환 =========\n",
    "def fetch_movie_info(cd: str):\n",
    "    js = kobis_get(\"/movie/searchMovieInfo\", {\"movieCd\": cd})\n",
    "    return js.get(\"movieInfoResult\",{}).get(\"movieInfo\",{}) or {}\n",
    "\n",
    "def is_korean_production(info) -> bool:\n",
    "    nations = [n.get(\"nationNm\") for n in (info.get(\"nations\") or []) if n.get(\"nationNm\")]\n",
    "    return any(str(n).strip() in {\"한국\",\"대한민국\",\"Korea\",\"South Korea\",\"Republic of Korea\"} for n in nations)\n",
    "\n",
    "def to_tmdb_row(cd, pool_rec, info):\n",
    "    movieNm   = info.get(\"movieNm\") or pool_rec.get(\"movieNm\")\n",
    "    movieNmEn = info.get(\"movieNmEn\") or movieNm\n",
    "    openDt    = info.get(\"openDt\") or pool_rec.get(\"openDt\")\n",
    "    iso       = to_iso_from_yyyymmdd(openDt)\n",
    "    dt        = pd.to_datetime(iso, errors=\"coerce\") if pd.notna(iso) else pd.NaT\n",
    "\n",
    "    showTm    = pd.to_numeric(info.get(\"showTm\"), errors=\"coerce\")\n",
    "    genres    = [g.get(\"genreNm\")   for g in (info.get(\"genres\")   or []) if g.get(\"genreNm\")]\n",
    "    companies = [c.get(\"companyNm\") for c in (info.get(\"companys\") or []) if c.get(\"companyNm\")]\n",
    "\n",
    "    return {\n",
    "        \"movie_id\": cd,\n",
    "        \"title\": movieNm,\n",
    "        \"original_title\": movieNmEn,\n",
    "        \"original_language\": \"ko\",\n",
    "        \"release_date\": iso,\n",
    "        \"runtime\": showTm,\n",
    "        \"budget\": pd.NA,\n",
    "        \"revenue\": float(pool_rec[\"max_sales\"]),       # 국내 최종 누적매출(원)\n",
    "        \"vote_average\": pd.NA,\n",
    "        \"vote_count\": pd.NA,\n",
    "        \"popularity\": pd.NA,\n",
    "        \"genres\": json_list_str(genres),\n",
    "        \"production_companies\": json_list_str(companies),\n",
    "        \"production_countries\": json_list_str([\"KR\"]),\n",
    "        \"release_year\": (dt.year  if pd.notna(dt) else pd.NA),\n",
    "        \"release_month\": (dt.month if pd.notna(dt) else pd.NA),\n",
    "        \"audience_total\": float(pool_rec[\"max_audi\"]), # 국내 최종 누적관객\n",
    "    }\n",
    "\n",
    "# ========= 3) 실행(재시작 가능) =========\n",
    "def main():\n",
    "    if not KOBIS_KEY:\n",
    "        raise SystemExit(\"❌ .env에 KOFIC_API_KEY(=KOBIS_KEY)가 없습니다.\")\n",
    "\n",
    "    # 1) 주간 스캔(캐시 활용)\n",
    "    if os.path.exists(WEEKLY_PICKLE):\n",
    "        pool = pd.read_pickle(WEEKLY_PICKLE)\n",
    "    else:\n",
    "        pool = weekly_scan()\n",
    "\n",
    "    # 주간에 한 번이라도 잡힌 영화만(=누적매출 추적 가능)\n",
    "    candidates = [cd for cd, rec in pool.items() if rec.get(\"max_sales\",0) > 0]\n",
    "\n",
    "    # 2) 이미 수집한 partial 읽기(재시작)\n",
    "    done = set()\n",
    "    if os.path.exists(OUT_PARTIAL):\n",
    "        prev = pd.read_csv(OUT_PARTIAL, dtype=str)\n",
    "        if \"movie_id\" in prev.columns:\n",
    "            done = set(prev[\"movie_id\"].astype(str).tolist())\n",
    "\n",
    "    todo = [cd for cd in candidates if cd not in done]\n",
    "    if not todo:\n",
    "        print(\"✅ 모두 처리됨. 최종 파일만 정리합니다.\")\n",
    "    else:\n",
    "        batch = todo[:MOVIES_PER_RUN]\n",
    "        print(f\"이번 배치: {len(batch)}편 / 남은 {len(todo)-len(batch)}편\")\n",
    "\n",
    "        rows = []\n",
    "        for cd in tqdm(batch, desc=\"movieInfo + merge (KR only)\"):\n",
    "            try:\n",
    "                info = fetch_movie_info(cd)\n",
    "                # 한국 제작 필터 + 개봉일(기간 내 안전망)\n",
    "                if not is_korean_production(info):\n",
    "                    continue\n",
    "                odt = info.get(\"openDt\") or pool[cd].get(\"openDt\")\n",
    "                if not odt or len(str(odt)) != 8:\n",
    "                    continue\n",
    "                # 기간 안전망 (열린 날짜 기준)\n",
    "                y, m, d = int(odt[:4]), int(odt[4:6]), int(odt[6:8])\n",
    "                opened = date(y,m,d)\n",
    "                if opened < START or opened > END:\n",
    "                    continue\n",
    "\n",
    "                row = to_tmdb_row(cd, pool[cd], info)\n",
    "                rows.append(row)\n",
    "            except Exception as e:\n",
    "                print(\"skip\", cd, e)\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows)\n",
    "            header = not os.path.exists(OUT_PARTIAL)\n",
    "            df.to_csv(OUT_PARTIAL, index=False, mode=(\"w\" if header else \"a\"),\n",
    "                      header=header, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 3) 최종 정리/저장(TMDB 스키마)\n",
    "    cols = [\"movie_id\",\"title\",\"original_title\",\"original_language\",\"release_date\",\"runtime\",\"budget\",\n",
    "            \"revenue\",\"vote_average\",\"vote_count\",\"popularity\",\"genres\",\"production_companies\",\n",
    "            \"production_countries\",\"release_year\",\"release_month\",\"audience_total\"]\n",
    "\n",
    "    part = pd.read_csv(OUT_PARTIAL, dtype=str) if os.path.exists(OUT_PARTIAL) else pd.DataFrame(columns=cols)\n",
    "    if not part.empty:\n",
    "        part[\"release_year\"]   = pd.to_numeric(part[\"release_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        part[\"release_month\"]  = pd.to_numeric(part[\"release_month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        part[\"runtime\"]        = pd.to_numeric(part[\"runtime\"], errors=\"coerce\")\n",
    "        part[\"revenue\"]        = pd.to_numeric(part[\"revenue\"], errors=\"coerce\")\n",
    "        part[\"audience_total\"] = pd.to_numeric(part[\"audience_total\"], errors=\"coerce\")\n",
    "        part = part.drop_duplicates(subset=[\"movie_id\"]).sort_values([\"release_year\",\"release_month\",\"title\"])\n",
    "\n",
    "    part.reindex(columns=cols).to_csv(OUT_FINAL, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ 저장: {OUT_FINAL} (rows={len(part):,})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
