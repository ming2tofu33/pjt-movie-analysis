{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259b23ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ…API KEY and TOKEN are set!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TMDB_API_KEY = os.getenv('TMDB_API_KEY')\n",
    "TMDB_API_TOKEN = os.getenv('TMDB_API_TOKEN')\n",
    "\n",
    "if TMDB_API_KEY and TMDB_API_TOKEN:\n",
    "    print('âœ…API KEY and TOKEN are set!')\n",
    "else:\n",
    "    print('âŒAPI KEY and TOKEN 404')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601c7378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) ID ìˆ˜ì§‘ (ğŸ‡°ğŸ‡· ì œì‘ âˆ© ğŸ‡°ğŸ‡· ê·¹ì¥ 2|3)â€¦\n",
      "â†’ ID ìˆ˜ì§‘ ë²”ìœ„: 2005-01-01 ~ 2025-06-30\n",
      "   ì˜ˆìƒ ì´ í˜ì´ì§€: 234 (ì´ í¸ìˆ˜ ì˜ˆìƒ: 4672)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 192\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… ì™„ë£Œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUT_CSV\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (rows=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 175\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m    174\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m1) ID ìˆ˜ì§‘ (ğŸ‡°ğŸ‡· ì œì‘ âˆ© ğŸ‡°ğŸ‡· ê·¹ì¥ 2|3)â€¦\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     ids = \u001b[43mcollect_all_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   â†’ ê³ ìœ  ID ìˆ˜: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m2) ìƒì„¸ ìˆ˜ì§‘ ì¤‘â€¦\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mcollect_all_ids\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=tp, desc=\u001b[33m\"\u001b[39m\u001b[33mDiscover pages (all range)\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m bar:\n\u001b[32m    107\u001b[39m     bar.update(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# page=1 ì²˜ë¦¬ ë°˜ì˜\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     more_ids, _, _ = \u001b[43mdiscover_ids_for_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSTART_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     ids = more_ids  \u001b[38;5;66;03m# discover_ids_for_range ì•ˆì—ì„œ page1ë¶€í„° ë‹¤ì‹œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ê·¸ê±¸ ì‚¬ìš©\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(ids))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mdiscover_ids_for_range\u001b[39m\u001b[34m(date_gte, date_lte, pbar)\u001b[39m\n\u001b[32m     74\u001b[39m p = common_params()\n\u001b[32m     75\u001b[39m p.update({\u001b[33m\"\u001b[39m\u001b[33mrelease_date.gte\u001b[39m\u001b[33m\"\u001b[39m: date_gte, \u001b[33m\"\u001b[39m\u001b[33mrelease_date.lte\u001b[39m\u001b[33m\"\u001b[39m: date_lte, \u001b[33m\"\u001b[39m\u001b[33mpage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m})\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m first = \u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBASE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/discover/movie\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m total_pages = \u001b[38;5;28mint\u001b[39m(first.get(\u001b[33m\"\u001b[39m\u001b[33mtotal_pages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m     78\u001b[39m ids = [m[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m first.get(\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m, [])]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mget_json\u001b[39m\u001b[34m(url, params, tries)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tries):\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTIMEOUT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m r.status_code \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m429\u001b[39m, \u001b[32m500\u001b[39m, \u001b[32m502\u001b[39m, \u001b[32m503\u001b[39m, \u001b[32m504\u001b[39m):\n\u001b[32m     42\u001b[39m             time.sleep(\u001b[38;5;28mmin\u001b[39m(\u001b[32m2\u001b[39m**i, \u001b[32m8\u001b[39m)); \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\connection.py:790\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m     \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[32m    788\u001b[39m     server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# If an error occurs during connection/handshake we may need to release\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# our lock so another connection can probe the origin.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\connection.py:969\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[32m    967\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    983\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:480\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n\u001b[32m    476\u001b[39m         context.load_cert_chain(certfile, keyfile, key_password)\n\u001b[32m    478\u001b[39m context.set_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m ssl_sock = \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amy\\Desktop\\projects\\pjt-movie-analysis\\venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:524\u001b[39m, in \u001b[36m_ssl_wrap_socket_impl\u001b[39m\u001b[34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[39m\n\u001b[32m    521\u001b[39m     SSLTransport._validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1076\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1073\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m timeout == \u001b[32m0.0\u001b[39m:\n\u001b[32m   1074\u001b[39m                 \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[32m   1075\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1078\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1372\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout == \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[32m   1371\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28mself\u001b[39m.settimeout(timeout)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "í•œêµ­ì—ì„œ ì œì‘ + í•œêµ­ ê·¹ì¥ ê°œë´‰(2|3) ì˜í™”ë§Œ ìˆ˜ì§‘ â†’ CSV ì €ì¥(ì§„í–‰ë¥  í‘œì‹œ)\n",
    "ê¸°ê°„: 2005-01-01 ~ 2025-06-30\n",
    "\"\"\"\n",
    "\n",
    "import os, time, datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ===================== ì„¤ì • =====================\n",
    "START_DATE = \"2005-01-01\"\n",
    "END_DATE   = \"2025-06-30\"\n",
    "\n",
    "LANG = \"ko-KR\"\n",
    "BASE = \"https://api.themoviedb.org/3\"\n",
    "SLEEP = 0.05                       # ìš”ì²­ ê°„ ë”œë ˆì´\n",
    "TIMEOUT = 30\n",
    "\n",
    "INCLUDE_ADULT = False              # ì„±ì¸ë¬¼ í¬í•¨í•˜ë ¤ë©´ True\n",
    "INCLUDE_VIDEO = False              # ë³´í†µ False ê¶Œì¥\n",
    "VOTE_COUNT_MIN = 10                # ë„ˆë¬´ ë§ˆì´ë„ˆ ì‘í’ˆ ì œê±°(ì›í•˜ë©´ 20/50 ë“±ìœ¼ë¡œ ì¡°ì •)\n",
    "\n",
    "OUT_CSV = \"data/processed/tmdb_kr_theatrical_2005_2025.csv\"\n",
    "\n",
    "# ===================== ì¤€ë¹„ =====================\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"TMDB_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise SystemExit(\"âŒ TMDB_API_KEYê°€ í™˜ê²½ë³€ìˆ˜(.env)ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
    "\n",
    "# ===================== ê³µí†µ ìœ í‹¸ =====================\n",
    "def get_json(url: str, params: dict, tries: int = 3):\n",
    "    for i in range(tries):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=TIMEOUT)\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                time.sleep(min(2**i, 8)); continue\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except requests.RequestException:\n",
    "            if i == tries - 1:\n",
    "                raise\n",
    "            time.sleep(min(2**i, 8))\n",
    "    raise RuntimeError(\"Unreachable\")\n",
    "\n",
    "def common_params():\n",
    "    return {\n",
    "        \"api_key\": API_KEY,\n",
    "        \"language\": LANG,\n",
    "        \"include_adult\": str(INCLUDE_ADULT).lower(),\n",
    "        \"include_video\": str(INCLUDE_VIDEO).lower(),\n",
    "        \"with_vote_count.gte\": VOTE_COUNT_MIN,\n",
    "        \"with_origin_country\": \"KR\",     # ğŸ‡°ğŸ‡· ì œì‘êµ­ í•œêµ­\n",
    "        \"region\": \"KR\",                  # ğŸ‡°ğŸ‡· ê°œë´‰ ì§€ì—­ í•œêµ­\n",
    "        \"with_release_type\": \"2|3\",      # ê·¹ì¥ ê°œë´‰(ì œí•œ/ì •ì‹)\n",
    "        \"sort_by\": \"release_date.asc\",   # í•œêµ­ ê°œë´‰ì¼ ê¸°ì¤€ ì •ë ¬\n",
    "        # release_date.gte/lteëŠ” í˜¸ì¶œ ì‹œ ì£¼ì…\n",
    "    }\n",
    "\n",
    "# ===================== 1) ID ìˆ˜ì§‘ =====================\n",
    "def discover_total_pages(date_gte: str, date_lte: str) -> int:\n",
    "    p = common_params()\n",
    "    p.update({\"release_date.gte\": date_gte, \"release_date.lte\": date_lte, \"page\": 1})\n",
    "    js = get_json(f\"{BASE}/discover/movie\", p)\n",
    "    return int(js.get(\"total_pages\", 1)), int(js.get(\"total_results\", 0)), js.get(\"results\", [])\n",
    "\n",
    "def discover_ids_for_range(date_gte: str, date_lte: str, pbar=None):\n",
    "    \"\"\"ë²”ìœ„ë¥¼ /discoverë¡œ ìˆ˜ì§‘. total_pages<=500ì´ë©´ í•œ ë²ˆì—, ì•„ë‹ˆë©´ í˜¸ì¶œìê°€ ìŠ¬ë¼ì´ìŠ¤.\"\"\"\n",
    "    p = common_params()\n",
    "    p.update({\"release_date.gte\": date_gte, \"release_date.lte\": date_lte, \"page\": 1})\n",
    "    first = get_json(f\"{BASE}/discover/movie\", p)\n",
    "    total_pages = int(first.get(\"total_pages\", 1))\n",
    "    ids = [m[\"id\"] for m in first.get(\"results\", [])]\n",
    "    if pbar: pbar.update(1)\n",
    "\n",
    "    for page in range(2, min(total_pages, 500) + 1):\n",
    "        p[\"page\"] = page\n",
    "        js = get_json(f\"{BASE}/discover/movie\", p)\n",
    "        ids.extend([m[\"id\"] for m in js.get(\"results\", [])])\n",
    "        if pbar: pbar.update(1)\n",
    "        time.sleep(SLEEP)\n",
    "    capped = total_pages > 500\n",
    "    return ids, capped, total_pages\n",
    "\n",
    "def year_slices(start: str, end: str):\n",
    "    s = dt.date.fromisoformat(start); e = dt.date.fromisoformat(end)\n",
    "    for y in range(s.year, e.year + 1):\n",
    "        y0 = dt.date(y, 1, 1); y1 = dt.date(y, 12, 31)\n",
    "        if y0 < s: y0 = s\n",
    "        if y1 > e: y1 = e\n",
    "        yield y0.isoformat(), y1.isoformat()\n",
    "\n",
    "def collect_all_ids():\n",
    "    print(\"â†’ ID ìˆ˜ì§‘ ë²”ìœ„:\", START_DATE, \"~\", END_DATE)\n",
    "    tp, tr, first_results = discover_total_pages(START_DATE, END_DATE)\n",
    "    print(f\"   ì˜ˆìƒ ì´ í˜ì´ì§€: {tp} (ì´ í¸ìˆ˜ ì˜ˆìƒ: {tr})\")\n",
    "\n",
    "    if tp <= 500:\n",
    "        # ì „ êµ¬ê°„ì„ í•œ ë²ˆì— ìˆ˜ì§‘ (í˜ì´ì§€ ê¸°ë°˜ ì§„í–‰ë°”)\n",
    "        ids = [m[\"id\"] for m in first_results]\n",
    "        with tqdm(total=tp, desc=\"Discover pages (all range)\", leave=False) as bar:\n",
    "            bar.update(1)  # page=1 ì²˜ë¦¬ ë°˜ì˜\n",
    "            more_ids, _, _ = discover_ids_for_range(START_DATE, END_DATE, pbar=bar)\n",
    "            ids = more_ids  # discover_ids_for_range ì•ˆì—ì„œ page1ë¶€í„° ë‹¤ì‹œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ê·¸ê±¸ ì‚¬ìš©\n",
    "        return sorted(set(ids))\n",
    "\n",
    "    # 500 ì´ˆê³¼ â†’ ì—° ë‹¨ìœ„ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜ì§‘ (ì—° ì „ì²´ í˜ì´ì§€ í•©ì‚°í•´ì„œ ì§„í–‰ë°” í‘œì‹œ)\n",
    "    # ë¨¼ì € ê° ì—°ë„ì˜ í˜ì´ì§€ ìˆ˜ë¥¼ íŒŒì•…í•´ í•©ì‚°\n",
    "    total_pages_sum = 0\n",
    "    year_meta = []\n",
    "    for yg, yl in year_slices(START_DATE, END_DATE):\n",
    "        pages, _, _ = discover_total_pages(yg, yl)\n",
    "        year_meta.append((yg, yl, pages))\n",
    "        total_pages_sum += min(pages, 500)\n",
    "    print(f\"   ì—° ë‹¨ìœ„ ìŠ¬ë¼ì´ìŠ¤ ì§„í–‰ (ì´ í˜ì´ì§€ í•©ì‚°: {total_pages_sum})\")\n",
    "\n",
    "    all_ids = set()\n",
    "    with tqdm(total=total_pages_sum, desc=\"Discover pages (by year)\", leave=False) as bar:\n",
    "        for yg, yl, pages in year_meta:\n",
    "            ids_y, _, _ = discover_ids_for_range(yg, yl, pbar=bar)\n",
    "            all_ids.update(ids_y)\n",
    "            time.sleep(SLEEP)\n",
    "    return sorted(all_ids)\n",
    "\n",
    "# ===================== 2) ìƒì„¸ ìˆ˜ì§‘ =====================\n",
    "def fetch_detail(mid: int):\n",
    "    params = {\"api_key\": API_KEY, \"language\": LANG}\n",
    "    try:\n",
    "        js = get_json(f\"{BASE}/movie/{mid}\", params)\n",
    "        time.sleep(SLEEP)\n",
    "        return js\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "# ===================== 3) ì •ê·œí™” â†’ CSV =====================\n",
    "def parse_genres(val):\n",
    "    return [x.get(\"name\") for x in val] if isinstance(val, list) else []\n",
    "\n",
    "def normalize_rows(rows):\n",
    "    df = pd.json_normalize(rows)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"movie_id\": df.get(\"id\"),\n",
    "        \"title\": df.get(\"title\"),\n",
    "        \"original_title\": df.get(\"original_title\"),\n",
    "        \"original_language\": df.get(\"original_language\"),\n",
    "        \"release_date\": df.get(\"release_date\"),\n",
    "        \"runtime\": pd.to_numeric(df.get(\"runtime\"), errors=\"coerce\"),\n",
    "        \"budget\": pd.to_numeric(df.get(\"budget\"), errors=\"coerce\"),\n",
    "        \"revenue\": pd.to_numeric(df.get(\"revenue\"), errors=\"coerce\"),\n",
    "        \"vote_average\": pd.to_numeric(df.get(\"vote_average\"), errors=\"coerce\"),\n",
    "        \"vote_count\": pd.to_numeric(df.get(\"vote_count\"), errors=\"coerce\"),\n",
    "        \"popularity\": pd.to_numeric(df.get(\"popularity\"), errors=\"coerce\"),\n",
    "        \"genres\": df.get(\"genres\").apply(parse_genres) if \"genres\" in df else [],\n",
    "        \"production_companies\": df.get(\"production_companies\").apply(\n",
    "            lambda xs: [x.get(\"name\") for x in xs] if isinstance(xs, list) else []\n",
    "        ) if \"production_companies\" in df else [],\n",
    "        \"production_countries\": df.get(\"production_countries\").apply(\n",
    "            lambda xs: [x.get(\"iso_3166_1\") for x in xs] if isinstance(xs, list) else []\n",
    "        ) if \"production_countries\" in df else [],\n",
    "    })\n",
    "    dt_series = pd.to_datetime(out[\"release_date\"], errors=\"coerce\")\n",
    "    out[\"release_year\"]  = dt_series.dt.year\n",
    "    out[\"release_month\"] = dt_series.dt.month\n",
    "    return out\n",
    "\n",
    "# ===================== ë©”ì¸ =====================\n",
    "def main():\n",
    "    print(\"1) ID ìˆ˜ì§‘ (ğŸ‡°ğŸ‡· ì œì‘ âˆ© ğŸ‡°ğŸ‡· ê·¹ì¥ 2|3)â€¦\")\n",
    "    ids = collect_all_ids()\n",
    "    print(f\"   â†’ ê³ ìœ  ID ìˆ˜: {len(ids):,}\")\n",
    "\n",
    "    print(\"2) ìƒì„¸ ìˆ˜ì§‘ ì¤‘â€¦\")\n",
    "    rows = []\n",
    "    with tqdm(total=len(ids), desc=\"Fetch details\", leave=False) as bar:\n",
    "        for mid in ids:\n",
    "            d = fetch_detail(mid)\n",
    "            if d: rows.append(d)\n",
    "            bar.update(1)\n",
    "\n",
    "    print(\"3) ì •ê·œí™” ë° CSV ì €ì¥â€¦\")\n",
    "    df = normalize_rows(rows)\n",
    "    df.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… ì™„ë£Œ: {OUT_CSV} (rows={len(df):,})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e307625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ í›„ë³´ ë¡œë“œ: ./data_processed/kofic_candidates_kr_2005_2025.csv (rows=2,100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detail + domestic totals:   0%|          | 0/2100 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mkobis_get\u001b[39m\u001b[34m(path, params, retry)\u001b[39m\n\u001b[32m     61\u001b[39m     fi  = data[\u001b[33m\"\u001b[39m\u001b[33mfaultInfo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKOBIS fault: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi.get(\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (code=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi.get(\u001b[33m'\u001b[39m\u001b[33merrorCode\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mURL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m time.sleep(SLEEP)\n",
      "\u001b[31mRuntimeError\u001b[39m: KOBIS fault: í‚¤ì˜ í•˜ë£¨ ì´ìš©ëŸ‰ì„ ì´ˆê³¼í•˜ì˜€ìŠµë‹ˆë‹¤. (code=320011)\nURL: https://www.kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieInfo.json?key=e361a2a2bd988422e95115026e8a7850&movieCd=20050120",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 366\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(CANDIDATES_CSV):\n\u001b[32m    365\u001b[39m     build_candidates()\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[43menrich_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 329\u001b[39m, in \u001b[36menrich_and_save\u001b[39m\u001b[34m(candidates_csv, out_csv)\u001b[39m\n\u001b[32m    327\u001b[39m movieCd = \u001b[38;5;28mstr\u001b[39m(r[\u001b[33m\"\u001b[39m\u001b[33mmovieCd\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     info = \u001b[43mfetch_movie_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovieCd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    331\u001b[39m     bar.update(\u001b[32m1\u001b[39m); \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 278\u001b[39m, in \u001b[36mfetch_movie_info\u001b[39m\u001b[34m(movieCd)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch_movie_info\u001b[39m(movieCd: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     js = \u001b[43mkobis_get\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/movie/searchMovieInfo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmovieCd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovieCd\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m js.get(\u001b[33m\"\u001b[39m\u001b[33mmovieInfoResult\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\u001b[33m\"\u001b[39m\u001b[33mmovieInfo\u001b[39m\u001b[33m\"\u001b[39m, {}) \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mkobis_get\u001b[39m\u001b[34m(path, params, retry)\u001b[39m\n\u001b[32m     68\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâŒ Request failed:\u001b[39m\u001b[33m\"\u001b[39m, e, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mURL:\u001b[39m\u001b[33m\"\u001b[39m, url)\n\u001b[32m     69\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33munreachable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "2005-01-01 ~ 2025-12-31\n",
    "KOFIC(KOBIS)ì—ì„œ 'í•œêµ­ ì œì‘ + êµ­ë‚´ ê·¹ì¥ ê°œë´‰' ì˜í™”ë§Œ í›„ë³´ ë‹¨ê³„ë¶€í„° ì„ ë³„í•˜ì—¬\n",
    "TMDB ìŠ¤íƒ€ì¼ ìŠ¤í‚¤ë§ˆ CSV ìƒì„± (revenue=êµ­ë‚´ ìµœì¢… ëˆ„ì ë§¤ì¶œ, audience_total=ìµœì¢… ëˆ„ì ê´€ê°)\n",
    "\n",
    "ì¶œë ¥ ì—´ ìˆœì„œ:\n",
    "movie_id,title,original_title,original_language,release_date,runtime,budget,\n",
    "revenue,vote_average,vote_count,popularity,genres,production_companies,\n",
    "production_countries,release_year,release_month,audience_total\n",
    "\"\"\"\n",
    "\n",
    "import os, time, json, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "from urllib.parse import urlencode\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ===== ì‚¬ìš©ì ì„¤ì • =====\n",
    "START_DATE = \"2005-01-01\"\n",
    "END_DATE   = \"2025-12-31\"\n",
    "\n",
    "OUT_DIR        = \"./data_processed\"\n",
    "CANDIDATES_CSV = f\"{OUT_DIR}/kofic_candidates_kr_2005_2025.csv\"   # í•œêµ­ë§Œ ë‹´ê¸´ í›„ë³´\n",
    "OUT_CSV        = f\"{OUT_DIR}/kofic_domestic_kr_2005_2025.csv\"     # ìµœì¢… ê²°ê³¼\n",
    "\n",
    "TIMEOUT = 20\n",
    "RETRY   = 3\n",
    "SLEEP   = 0.15  # ë„ˆë¬´ ë‚®ì¶”ë©´ 429 ìœ„í—˜\n",
    "\n",
    "# ì£¼ê°„ ë°•ìŠ¤ì˜¤í”¼ìŠ¤ ê¸°ë°˜ ìµœì¢… ëˆ„ì  ì¶”ì • íŒŒë¼ë¯¸í„°\n",
    "JUMP_STEPS_DAYS     = [0, 14, 28, 56, 84]  # ê°œë´‰ í›„ 0/2/4/8/12ì£¼\n",
    "LOCAL_REFINE_RADIUS = 7                    # ë§ˆì§€ë§‰ ì•µì»¤ Â±1ì£¼ ë³´ì •\n",
    "MIN_ABS_DELTA  = 50_000_000               # ë§¤ì¶œ ì¦ê°€ ìµœì†Œì¹˜(ì›)\n",
    "MIN_REL_DELTA  = 0.01                     # ì¦ê°€ìœ¨ ì„ê³„(1%)\n",
    "PLATEAU_STREAK = 2                        # 2íšŒ ì—°ì† ì •ì²´ â†’ ì¢…ë£Œ\n",
    "\n",
    "# ===== ì¤€ë¹„ =====\n",
    "load_dotenv()\n",
    "KOFIC_KEY = os.getenv(\"KOFIC_API_KEY\") or os.getenv(\"KOBIS_KEY\")\n",
    "if not KOFIC_KEY:\n",
    "    raise SystemExit(\"âŒ .envì— KOFIC_API_KEY(=KOBIS_KEY)ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "BASE = \"https://www.kobis.or.kr/kobisopenapi/webservice/rest\"\n",
    "\n",
    "def kobis_get(path, params, retry=RETRY):\n",
    "    q = {\"key\": KOFIC_KEY, **params}\n",
    "    url = f\"{BASE}{path}.json?{urlencode(q)}\"\n",
    "    last_err = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=TIMEOUT)\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                time.sleep(min(2**i, 8)); continue\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if isinstance(data, dict) and data.get(\"faultInfo\"):\n",
    "                fi  = data[\"faultInfo\"]\n",
    "                raise RuntimeError(f\"KOBIS fault: {fi.get('message')} (code={fi.get('errorCode')})\\nURL: {url}\")\n",
    "            time.sleep(SLEEP)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            if i == retry - 1:\n",
    "                print(\"âŒ Request failed:\", e, \"\\nURL:\", url)\n",
    "                raise\n",
    "            time.sleep(min(2**i, 8))\n",
    "    raise RuntimeError(f\"unreachable: {last_err}\")\n",
    "\n",
    "# ===== ê³µí†µ ìœ í‹¸ =====\n",
    "def to_iso_from_yyyymmdd(s):\n",
    "    if not s: return pd.NA\n",
    "    s = str(s)\n",
    "    if len(s) != 8 or not s.isdigit(): return pd.NA\n",
    "    return f\"{s[:4]}-{s[4:6]}-{s[6:]}\"\n",
    "\n",
    "def json_list_str(xs):\n",
    "    if xs is None: return \"[]\"\n",
    "    if isinstance(xs, list):\n",
    "        return json.dumps(xs, ensure_ascii=False)\n",
    "    return json.dumps([str(xs)], ensure_ascii=False)\n",
    "\n",
    "def sunday_of_week(d: date) -> date:\n",
    "    # ì›”=0..ì¼=6 â†’ ì¼ìš”ì¼ë¡œ ë³´ì •\n",
    "    return d + timedelta(days=(6 - d.weekday()))\n",
    "\n",
    "def is_korean_production(info):\n",
    "    nations = [n.get(\"nationNm\") for n in (info.get(\"nations\") or []) if n.get(\"nationNm\")]\n",
    "    return any(str(n).strip() in {\"í•œêµ­\",\"ëŒ€í•œë¯¼êµ­\",\"Korea\",\"South Korea\",\"Republic of Korea\"} for n in nations)\n",
    "\n",
    "def in_period_open(info, start=START_DATE, end=END_DATE):\n",
    "    openDt = info.get(\"openDt\")\n",
    "    if not openDt: return False\n",
    "    iso = to_iso_from_yyyymmdd(openDt)\n",
    "    if pd.isna(iso): return False\n",
    "    return (iso >= start) and (iso <= end)\n",
    "\n",
    "# ===== (ì˜µì…˜2) ê³µí†µì½”ë“œì—ì„œ â€˜í•œêµ­â€™ 8ìë¦¬ ì½”ë“œ ì¡°íšŒ =====\n",
    "# ì—ëŸ¬ ë©”ì‹œì§€ì— â€˜ê³µí†µì½”ë“œ220310â€™ì´ ì–¸ê¸‰ë˜ëŠ” ê²½ìš°ê°€ ìˆì–´ ë‹¤ì–‘í•œ í›„ë³´ comCodeë¥¼ ìˆœíšŒ íƒìƒ‰\n",
    "CODE_TABLE_CANDIDATES = [\"220310\", \"2204\", \"22003\", \"2203\", \"220301\", \"220201\"]\n",
    "\n",
    "def get_korea_code(verbose=True):\n",
    "    for cc in CODE_TABLE_CANDIDATES:\n",
    "        try:\n",
    "            js = kobis_get(\"/code/searchCodeList\", {\"comCode\": cc})\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  Â· ê³µí†µì½”ë“œ {cc} ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "\n",
    "        # ì‘ë‹µ êµ¬ì¡° ê°€ë³€ ëŒ€ì‘\n",
    "        code_list = (\n",
    "            (js.get(\"codeListResult\") or {}).get(\"codeList\")\n",
    "            or js.get(\"codes\")\n",
    "            or js.get(\"codeList\")\n",
    "            or []\n",
    "        )\n",
    "\n",
    "        found = None\n",
    "        for c in code_list:\n",
    "            name_ko = c.get(\"korNm\") or c.get(\"codeNm\") or c.get(\"korName\") or \"\"\n",
    "            name_en = (c.get(\"engNm\") or c.get(\"engName\") or \"\").upper()\n",
    "            code    = c.get(\"fullCd\") or c.get(\"code\") or c.get(\"cd\") or \"\"\n",
    "            if ((\"í•œêµ­\" in name_ko) or (\"ëŒ€í•œë¯¼êµ­\" in name_ko)\n",
    "                or (\"KOREA\" in name_en) or (\"REPUBLIC OF KOREA\" in name_en)):\n",
    "                if isinstance(code, str) and len(code) == 8 and code.isdigit():\n",
    "                    found = code; break\n",
    "\n",
    "        if found:\n",
    "            if verbose:\n",
    "                print(f\"âœ… í•œêµ­ ì½”ë“œ ë°œê²¬ (comCode={cc}): {found}\")\n",
    "            return found\n",
    "\n",
    "    if verbose:\n",
    "        print(\"âš ï¸ ê³µí†µì½”ë“œ í…Œì´ë¸”ì—ì„œ í•œêµ­ ì½”ë“œ(8ìë¦¬)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ í•„í„° í´ë°±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    return None\n",
    "\n",
    "# ===== 1) í›„ë³´(ì—°ë„ë³„) ìˆ˜ì§‘: â€˜ì„œë²„ í•„í„°(í•œêµ­)â€™ ìš°ì„ , ì‹¤íŒ¨ì‹œ í´ë°±(ì‘ë‹µì—ì„œ í•œêµ­ë§Œ ì„ ë³„) =====\n",
    "KR_LABELS = {\"í•œêµ­\",\"ëŒ€í•œë¯¼êµ­\",\"Korea\",\"South Korea\",\"Republic of Korea\"}\n",
    "\n",
    "def find_candidates_by_year(year: int, kr_code: str | None):\n",
    "    y = str(year)\n",
    "    # ìš°ì„  â€˜ì—°/ê¸°ê°„â€™ 3ê°€ì§€ íŒ¨í„´ìœ¼ë¡œ í”„ë¡œë¸Œ â†’ ì„±ê³µ ì¡°í•©ìœ¼ë¡œ í˜ì´ì§•\n",
    "    base_patterns = [\n",
    "        {\"openStartDt\": y,          \"openEndDt\": y          },\n",
    "        {\"openStartDt\": y                                  },\n",
    "        {\"openStartDt\": f\"{y}0101\", \"openEndDt\": f\"{y}1231\"},\n",
    "    ]\n",
    "\n",
    "    def probe(params):\n",
    "        js = kobis_get(\"/movie/searchMovieList\", {**params, \"itemPerPage\": 10, \"curPage\": 1})\n",
    "        res = js.get(\"movieListResult\", {}) or {}\n",
    "        tot = res.get(\"totCnt\")\n",
    "        return int(tot) if (isinstance(tot, (int,str)) and str(tot).isdigit()) else 0\n",
    "\n",
    "    chosen = None\n",
    "    mode = \"ANY\"\n",
    "\n",
    "    # 1) repNationCd=í•œêµ­ì½”ë“œ ì‚¬ìš© í”„ë¡œë¸Œ\n",
    "    if kr_code:\n",
    "        for p in base_patterns:\n",
    "            params = {**p, \"repNationCd\": kr_code}\n",
    "            if probe(params) > 0:\n",
    "                chosen = params\n",
    "                mode = \"KCODE\"\n",
    "                break\n",
    "\n",
    "    # 2) ì‹¤íŒ¨ ì‹œ ë¬´í•„í„°ë¡œ í”„ë¡œë¸Œ\n",
    "    if chosen is None:\n",
    "        for p in base_patterns:\n",
    "            if probe(p) > 0:\n",
    "                chosen = p\n",
    "                mode = \"ANY\"\n",
    "                break\n",
    "\n",
    "    if chosen is None:\n",
    "        print(f\"  Â· {year}: í›„ë³´ 0ê±´ (ê±´ë„ˆëœ€)\")\n",
    "        return []\n",
    "\n",
    "    out, per_page, cur_page, total_seen = [], 100, 1, None\n",
    "    while True:\n",
    "        params = {**chosen, \"itemPerPage\": per_page, \"curPage\": cur_page}\n",
    "        js = kobis_get(\"/movie/searchMovieList\", params)\n",
    "        res = js.get(\"movieListResult\", {}) or {}\n",
    "        lst = res.get(\"movieList\", []) or []\n",
    "        tot = res.get(\"totCnt\", None)\n",
    "        if total_seen is None and tot is not None:\n",
    "            total_seen = int(tot)\n",
    "\n",
    "        if not lst: break\n",
    "\n",
    "        for x in lst:\n",
    "            mc  = x.get(\"movieCd\")\n",
    "            rep = (x.get(\"repNationNm\") or \"\").strip()\n",
    "            if not mc:\n",
    "                continue\n",
    "            if (mode == \"KCODE\") or (rep in KR_LABELS):\n",
    "                out.append((mc, x.get(\"movieNm\"), x.get(\"openDt\")))\n",
    "\n",
    "        # repNationCdë¥¼ ì“´ ê²½ìš°ì—ëŠ” totCntì— ì‹ ë¢°\n",
    "        if (mode == \"KCODE\") and (total_seen is not None) and (len(out) >= total_seen):\n",
    "            break\n",
    "\n",
    "        cur_page += 1\n",
    "        time.sleep(SLEEP)\n",
    "\n",
    "    print(f\"  Â· {year}: mode={mode:<6}, collected(K-only)={len(out):>5}\")\n",
    "    return out\n",
    "\n",
    "def build_candidates(save_path=CANDIDATES_CSV, start=START_DATE, end=END_DATE):\n",
    "    s_year, e_year = int(start[:4]), int(end[:4])\n",
    "    print(\"ì—°ë„ë³„ í›„ë³´ ìˆ˜ì§‘(ì„œë²„ í•œêµ­ì½”ë“œ ìš°ì„ )â€¦\")\n",
    "    kr_code = get_korea_code(verbose=True)\n",
    "    cands = []\n",
    "    for y in range(s_year, e_year+1):\n",
    "        cands.extend(find_candidates_by_year(y, kr_code))\n",
    "    df = pd.DataFrame(cands, columns=[\"movieCd\",\"movieNm\",\"openDt\"]).drop_duplicates(\"movieCd\")\n",
    "    df.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“„ í›„ë³´ ì €ì¥(í•œêµ­ë§Œ): {save_path} (ê³ ìœ  {len(df):,}í¸)\")\n",
    "    return df\n",
    "\n",
    "# ===== 2) ì£¼ê°„ ë°•ìŠ¤ì˜¤í”¼ìŠ¤ ê¸°ë°˜ ëˆ„ì (ë§¤ì¶œ/ê´€ê°) ì¶”ì • =====\n",
    "weekly_cache = {}\n",
    "\n",
    "def weekly_items(target_yyyymmdd: str):\n",
    "    if target_yyyymmdd in weekly_cache:\n",
    "        return weekly_cache[target_yyyymmdd]\n",
    "    js = kobis_get(\"/boxoffice/searchWeeklyBoxOfficeList\",\n",
    "                   {\"targetDt\": target_yyyymmdd, \"weekGb\": \"0\"})\n",
    "    items = js.get(\"boxOfficeResult\", {}).get(\"weeklyBoxOfficeList\", []) or []\n",
    "    weekly_cache[target_yyyymmdd] = items\n",
    "    return items\n",
    "\n",
    "def get_acc_from_weekly_by_code(movieCd: str, target_date: date):\n",
    "    tgt = sunday_of_week(target_date).strftime(\"%Y%m%d\")\n",
    "    for it in weekly_items(tgt):\n",
    "        if it.get(\"movieCd\") == movieCd:\n",
    "            s = pd.to_numeric(it.get(\"salesAcc\"), errors=\"coerce\") or 0\n",
    "            a = pd.to_numeric(it.get(\"audiAcc\"),  errors=\"coerce\") or 0\n",
    "            return s, a\n",
    "    return 0, 0\n",
    "\n",
    "def intelligent_final_acc(movieCd: str, open_yyyymmdd: str):\n",
    "    if not open_yyyymmdd or len(str(open_yyyymmdd)) != 8:\n",
    "        return (pd.NA, pd.NA)\n",
    "    base = datetime.strptime(open_yyyymmdd, \"%Y%m%d\").date()\n",
    "\n",
    "    best_sales, best_audi = 0.0, 0.0\n",
    "    plateau_cnt, prev = 0, 0.0\n",
    "\n",
    "    for dd in JUMP_STEPS_DAYS:\n",
    "        anchor = base + timedelta(days=dd)\n",
    "        s, a = get_acc_from_weekly_by_code(movieCd, anchor)\n",
    "        if s > best_sales: best_sales = s\n",
    "        if a > best_audi:  best_audi  = a\n",
    "\n",
    "        delta = best_sales - prev\n",
    "        rel = (delta/prev) if prev > 0 else 1.0\n",
    "        plateau_cnt = plateau_cnt + 1 if (delta < MIN_ABS_DELTA and rel < MIN_REL_DELTA) else 0\n",
    "        prev = best_sales\n",
    "\n",
    "        if plateau_cnt >= PLATEAU_STREAK:\n",
    "            for d in range(-LOCAL_REFINE_RADIUS, LOCAL_REFINE_RADIUS+1, 7):\n",
    "                anchor2 = anchor + timedelta(days=d)\n",
    "                s2, a2 = get_acc_from_weekly_by_code(movieCd, anchor2)\n",
    "                if s2 > best_sales: best_sales = s2\n",
    "                if a2 > best_audi:  best_audi  = a2\n",
    "            break\n",
    "\n",
    "    return (pd.NA if best_sales == 0 else best_sales,\n",
    "            pd.NA if best_audi  == 0 else best_audi)\n",
    "\n",
    "# ===== 3) ìƒì„¸ â†’ TMDB ìŠ¤íƒ€ì¼ í–‰ ë¹Œë“œ =====\n",
    "def fetch_movie_info(movieCd: str):\n",
    "    js = kobis_get(\"/movie/searchMovieInfo\", {\"movieCd\": movieCd})\n",
    "    return js.get(\"movieInfoResult\", {}).get(\"movieInfo\", {}) or {}\n",
    "\n",
    "def to_tmdb_row(info, salesAcc_final, audiAcc_final):\n",
    "    movieCd   = info.get(\"movieCd\")\n",
    "    movieNm   = info.get(\"movieNm\")\n",
    "    movieNmEn = info.get(\"movieNmEn\") or movieNm\n",
    "    openDt    = info.get(\"openDt\")  # yyyymmdd\n",
    "    release_date = to_iso_from_yyyymmdd(openDt)\n",
    "\n",
    "    dt = pd.to_datetime(release_date, errors=\"coerce\") if pd.notna(release_date) else pd.NaT\n",
    "    release_year  = (dt.year  if pd.notna(dt) else pd.NA)\n",
    "    release_month = (dt.month if pd.notna(dt) else pd.NA)\n",
    "\n",
    "    showTm = pd.to_numeric(info.get(\"showTm\"), errors=\"coerce\")\n",
    "    genres    = [g.get(\"genreNm\")   for g in (info.get(\"genres\")   or []) if g.get(\"genreNm\")]\n",
    "    companies = [c.get(\"companyNm\") for c in (info.get(\"companys\") or []) if c.get(\"companyNm\")]\n",
    "\n",
    "    return {\n",
    "        \"movie_id\": movieCd,\n",
    "        \"title\": movieNm,\n",
    "        \"original_title\": movieNmEn,\n",
    "        \"original_language\": \"ko\",\n",
    "        \"release_date\": release_date,\n",
    "        \"runtime\": showTm,\n",
    "        \"budget\": pd.NA,\n",
    "        \"revenue\": pd.to_numeric(salesAcc_final),  # êµ­ë‚´ ìµœì¢… ëˆ„ì ë§¤ì¶œ(ì›)\n",
    "        \"vote_average\": pd.NA,\n",
    "        \"vote_count\": pd.NA,\n",
    "        \"popularity\": pd.NA,\n",
    "        \"genres\": json_list_str(genres),\n",
    "        \"production_companies\": json_list_str(companies),\n",
    "        \"production_countries\": json_list_str([\"KR\"]),\n",
    "        \"release_year\": release_year,\n",
    "        \"release_month\": release_month,\n",
    "        \"audience_total\": pd.to_numeric(audiAcc_final),  # êµ­ë‚´ ìµœì¢… ëˆ„ì ê´€ê°\n",
    "    }\n",
    "\n",
    "def enrich_and_save(candidates_csv=CANDIDATES_CSV, out_csv=OUT_CSV):\n",
    "    # í›„ë³´ ë¡œë“œ or ìƒì„±\n",
    "    if os.path.exists(candidates_csv):\n",
    "        cand = pd.read_csv(candidates_csv, dtype=str)\n",
    "        print(f\"ğŸ“„ í›„ë³´ ë¡œë“œ: {candidates_csv} (rows={len(cand):,})\")\n",
    "    else:\n",
    "        cand = build_candidates()\n",
    "\n",
    "    rows = []\n",
    "    with tqdm(total=len(cand), desc=\"Detail + domestic totals\") as bar:\n",
    "        for _, r in cand.iterrows():\n",
    "            movieCd = str(r[\"movieCd\"])\n",
    "            try:\n",
    "                info = fetch_movie_info(movieCd)\n",
    "            except Exception:\n",
    "                bar.update(1); continue\n",
    "\n",
    "            # ìƒì„¸ì—ì„œë„ í•œêµ­ ì œì‘ & ê¸°ê°„ ë‚´ ê°œë´‰ í™•ì¸ (ì´ì¤‘ ì•ˆì „ë§)\n",
    "            if (not is_korean_production(info)) or (not in_period_open(info)):\n",
    "                bar.update(1); continue\n",
    "\n",
    "            try:\n",
    "                s_final, a_final = intelligent_final_acc(movieCd, info.get(\"openDt\"))\n",
    "            except Exception:\n",
    "                s_final, a_final = (pd.NA, pd.NA)\n",
    "\n",
    "            rows.append(to_tmdb_row(info, s_final, a_final))\n",
    "            bar.update(1)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df[\"runtime\"]        = pd.to_numeric(df[\"runtime\"], errors=\"coerce\")\n",
    "        df[\"revenue\"]        = pd.to_numeric(df[\"revenue\"], errors=\"coerce\")\n",
    "        df[\"audience_total\"] = pd.to_numeric(df[\"audience_total\"], errors=\"coerce\")\n",
    "        df[\"release_year\"]   = pd.to_numeric(df[\"release_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        df[\"release_month\"]  = pd.to_numeric(df[\"release_month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    cols = [\"movie_id\",\"title\",\"original_title\",\"original_language\",\"release_date\",\"runtime\",\"budget\",\n",
    "            \"revenue\",\"vote_average\",\"vote_count\",\"popularity\",\"genres\",\"production_companies\",\n",
    "            \"production_countries\",\"release_year\",\"release_month\",\"audience_total\"]\n",
    "    df = df.reindex(columns=cols)\n",
    "\n",
    "    df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {out_csv} (rows={len(df):,})\")\n",
    "    print(f\"ğŸ—ƒ weekly_cache í¬ê¸°(ì•µì»¤ í˜¸ì¶œ ìˆ˜): {len(weekly_cache):,}\")\n",
    "\n",
    "# ===== ì‹¤í–‰ =====\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(CANDIDATES_CSV):\n",
    "        build_candidates()\n",
    "    enrich_and_save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59434400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kofic_resume_from_candidates.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, time, json, requests, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "from urllib.parse import urlencode\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ========= ì„¤ì • =========\n",
    "CANDIDATES_CSV = \"./data_processed/kofic_candidates_kr_2005_2025.csv\"   # ì´ë¯¸ í™•ë³´í•œ í›„ë³´ ëª©ë¡\n",
    "OUT_PARTIAL    = \"./data_processed/kofic_domestic_partial.csv\"          # ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ì´ì–´ë¶™ì„\n",
    "DONE_IDS_TXT   = \"./data_processed/kofic_done_ids.txt\"                  # ì²˜ë¦¬ ì™„ë£Œ id ê¸°ë¡\n",
    "OUT_FINAL      = \"./data_processed/kofic_domestic_final.csv\"            # ìµœì¢… ë¨¸ì§€ë³¸ (ì›í•˜ëŠ” ì‹œì ì— ìƒì„±)\n",
    "\n",
    "TIMEOUT = 20\n",
    "RETRY   = 3\n",
    "SLEEP   = 0.15\n",
    "\n",
    "# ìš”ì²­ ì˜ˆì‚°(ëŒ€ëµ): ì˜í™” 1í¸ë‹¹ ~6~12íšŒ í˜¸ì¶œ(ì •ë³´ 1 + ì£¼ê°„ 5~10)\n",
    "# ì˜¤ëŠ˜ ë‚¨ì€ í˜¸ì¶œì„ ë„‰ë„‰íˆ ë³´ìˆ˜ì ìœ¼ë¡œ ì¡ì•„ MOVIES_PER_RUN ë§Œí¼ë§Œ ì²˜ë¦¬\n",
    "MOVIES_PER_RUN = 120  # í•œ ë²ˆ ì‹¤í–‰ì— ì²˜ë¦¬í•  ìµœëŒ€ ì˜í™” ê°œìˆ˜ (ìƒí™©ì— ë§ê²Œ ì¡°ì ˆ)\n",
    "\n",
    "# ì£¼ê°„ ë°•ìŠ¤ì˜¤í”¼ìŠ¤ ì í”„ ì•µì»¤(ê°œë´‰ í›„ ê²½ê³¼ì¼)\n",
    "JUMP_STEPS_DAYS     = [0, 14, 28, 56]  # í•„ìš”í•˜ë©´ 84 ì¶”ê°€\n",
    "LOCAL_REFINE_RADIUS = 7\n",
    "MIN_ABS_DELTA  = 50_000_000  # ì› ë‹¨ìœ„ ìµœì†Œ ì¦ê°€ëŸ‰\n",
    "MIN_REL_DELTA  = 0.01        # 1%\n",
    "PLATEAU_STREAK = 2\n",
    "\n",
    "load_dotenv()\n",
    "KOFIC_KEY = os.getenv(\"KOFIC_API_KEY\") or os.getenv(\"KOBIS_KEY\")\n",
    "BASE = \"https://www.kobis.or.kr/kobisopenapi/webservice/rest\"\n",
    "os.makedirs(os.path.dirname(OUT_PARTIAL), exist_ok=True)\n",
    "\n",
    "def kobis_get(path, params, retry=RETRY):\n",
    "    q = {\"key\": KOFIC_KEY, **params}\n",
    "    url = f\"{BASE}{path}.json?{urlencode(q)}\"\n",
    "    last = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=TIMEOUT)\n",
    "            if r.status_code in (429,500,502,503,504):\n",
    "                time.sleep(min(2**i,8)); continue\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if data.get(\"faultInfo\"):\n",
    "                fi = data[\"faultInfo\"]\n",
    "                raise RuntimeError(f\"KOBIS fault: {fi.get('message')} (code={fi.get('errorCode')})\")\n",
    "            time.sleep(SLEEP)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            if i == retry-1: raise\n",
    "            time.sleep(min(2**i,8))\n",
    "    raise RuntimeError(last)\n",
    "\n",
    "def sunday_of_week(d: date) -> date:\n",
    "    return d + timedelta(days=(6 - d.weekday()))\n",
    "\n",
    "def weekly_items(target_yyyymmdd: str, cache: dict):\n",
    "    if target_yyyymmdd in cache:\n",
    "        return cache[target_yyyymmdd]\n",
    "    js = kobis_get(\"/boxoffice/searchWeeklyBoxOfficeList\", {\"targetDt\": target_yyyymmdd, \"weekGb\":\"0\"})\n",
    "    items = js.get(\"boxOfficeResult\", {}).get(\"weeklyBoxOfficeList\", []) or []\n",
    "    cache[target_yyyymmdd] = items\n",
    "    return items\n",
    "\n",
    "def get_acc_from_weekly_by_code(movieCd: str, anchor_date: date, cache: dict):\n",
    "    tgt = sunday_of_week(anchor_date).strftime(\"%Y%m%d\")\n",
    "    for it in weekly_items(tgt, cache):\n",
    "        if it.get(\"movieCd\") == movieCd:\n",
    "            s = pd.to_numeric(it.get(\"salesAcc\"), errors=\"coerce\") or 0\n",
    "            a = pd.to_numeric(it.get(\"audiAcc\"),  errors=\"coerce\") or 0\n",
    "            return s, a\n",
    "    return 0, 0\n",
    "\n",
    "def intelligent_final_acc(movieCd: str, open_yyyymmdd: str, cache: dict):\n",
    "    if not open_yyyymmdd or len(str(open_yyyymmdd))!=8:\n",
    "        return (pd.NA, pd.NA)\n",
    "    base = datetime.strptime(open_yyyymmdd, \"%Y%m%d\").date()\n",
    "\n",
    "    best_sales, best_audi = 0.0, 0.0\n",
    "    plateau_cnt, prev = 0, 0.0\n",
    "\n",
    "    for dd in JUMP_STEPS_DAYS:\n",
    "        anchor = base + timedelta(days=dd)\n",
    "        s, a = get_acc_from_weekly_by_code(movieCd, anchor, cache)\n",
    "        if s > best_sales: best_sales = s\n",
    "        if a > best_audi:  best_audi  = a\n",
    "\n",
    "        delta = best_sales - prev\n",
    "        rel = (delta/prev) if prev>0 else 1.0\n",
    "        plateau_cnt = plateau_cnt + 1 if (delta < MIN_ABS_DELTA and rel < MIN_REL_DELTA) else 0\n",
    "        prev = best_sales\n",
    "\n",
    "        if plateau_cnt >= PLATEAU_STREAK:\n",
    "            for d in range(-LOCAL_REFINE_RADIUS, LOCAL_REFINE_RADIUS+1, 7):\n",
    "                anchor2 = anchor + timedelta(days=d)\n",
    "                s2, a2 = get_acc_from_weekly_by_code(movieCd, anchor2, cache)\n",
    "                if s2 > best_sales: best_sales = s2\n",
    "                if a2 > best_audi:  best_audi  = a2\n",
    "            break\n",
    "\n",
    "    return (pd.NA if best_sales==0 else best_sales,\n",
    "            pd.NA if best_audi==0  else best_audi)\n",
    "\n",
    "def to_iso_from_yyyymmdd(s):\n",
    "    if not s: return pd.NA\n",
    "    s=str(s)\n",
    "    return f\"{s[:4]}-{s[4:6]}-{s[6:]}\" if len(s)>=8 else pd.NA\n",
    "\n",
    "def json_list_str(xs):\n",
    "    if xs is None: return \"[]\"\n",
    "    if isinstance(xs, list): return json.dumps(xs, ensure_ascii=False)\n",
    "    return json.dumps([str(xs)], ensure_ascii=False)\n",
    "\n",
    "def fetch_movie_info(movieCd: str):\n",
    "    js = kobis_get(\"/movie/searchMovieInfo\", {\"movieCd\": movieCd})\n",
    "    return js.get(\"movieInfoResult\", {}).get(\"movieInfo\", {}) or {}\n",
    "\n",
    "def to_tmdb_row(info, salesAcc_final, audiAcc_final):\n",
    "    movieCd   = info.get(\"movieCd\")\n",
    "    movieNm   = info.get(\"movieNm\")\n",
    "    movieNmEn = info.get(\"movieNmEn\") or movieNm\n",
    "    openDt    = info.get(\"openDt\")  # yyyymmdd\n",
    "    iso       = to_iso_from_yyyymmdd(openDt)\n",
    "    dt        = pd.to_datetime(iso, errors=\"coerce\") if pd.notna(iso) else pd.NaT\n",
    "    release_year  = (dt.year  if pd.notna(dt) else pd.NA)\n",
    "    release_month = (dt.month if pd.notna(dt) else pd.NA)\n",
    "    showTm = pd.to_numeric(info.get(\"showTm\"), errors=\"coerce\")\n",
    "\n",
    "    genres    = [g.get(\"genreNm\")   for g in (info.get(\"genres\")   or []) if g.get(\"genreNm\")]\n",
    "    companies = [c.get(\"companyNm\") for c in (info.get(\"companys\") or []) if c.get(\"companyNm\")]\n",
    "\n",
    "    return {\n",
    "        \"movie_id\": movieCd,\n",
    "        \"title\": movieNm,\n",
    "        \"original_title\": movieNmEn,\n",
    "        \"original_language\": \"ko\",\n",
    "        \"release_date\": iso,\n",
    "        \"runtime\": showTm,\n",
    "        \"budget\": pd.NA,\n",
    "        \"revenue\": pd.to_numeric(salesAcc_final),\n",
    "        \"vote_average\": pd.NA,\n",
    "        \"vote_count\": pd.NA,\n",
    "        \"popularity\": pd.NA,\n",
    "        \"genres\": json_list_str(genres),\n",
    "        \"production_companies\": json_list_str(companies),\n",
    "        \"production_countries\": json_list_str([\"KR\"]),\n",
    "        \"release_year\": release_year,\n",
    "        \"release_month\": release_month,\n",
    "        \"audience_total\": pd.to_numeric(audiAcc_final),\n",
    "    }\n",
    "\n",
    "def load_done_ids():\n",
    "    if not os.path.exists(DONE_IDS_TXT):\n",
    "        return set()\n",
    "    with open(DONE_IDS_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "        return set(line.strip() for line in f if line.strip())\n",
    "\n",
    "def append_done_id(mid: str):\n",
    "    with open(DONE_IDS_TXT, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(mid+\"\\n\")\n",
    "\n",
    "def append_partial_row(row: dict):\n",
    "    df = pd.DataFrame([row])\n",
    "    header = not os.path.exists(OUT_PARTIAL)\n",
    "    df.to_csv(OUT_PARTIAL, index=False, mode=(\"w\" if header else \"a\"),\n",
    "              header=header, encoding=\"utf-8-sig\")\n",
    "\n",
    "def main():\n",
    "    if not KOFIC_KEY:\n",
    "        raise SystemExit(\"âŒ .envì— KOFIC_API_KEY(=KOBIS_KEY)ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    cand = pd.read_csv(CANDIDATES_CSV, dtype=str)\n",
    "    done = load_done_ids()\n",
    "\n",
    "    # ì²˜ë¦¬ ëŒ€ìƒ = ì•„ì§ ì•ˆ í•œ movieCd\n",
    "    todo = [mc for mc in cand[\"movieCd\"].astype(str).unique() if mc not in done]\n",
    "    if not todo:\n",
    "        print(\"ëª¨ë“  í›„ë³´ê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # ì˜¤ëŠ˜ ì‹¤í–‰ì— ì²˜ë¦¬í•  ë°°ì¹˜\n",
    "    batch = todo[:MOVIES_PER_RUN]\n",
    "    print(f\"ì´ë²ˆ ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆì •: {len(batch)}í¸  (ë‚¨ì€ í›„ë³´ {len(todo)-len(batch)}í¸)\")\n",
    "\n",
    "    cache = {}\n",
    "    with tqdm(total=len(batch), desc=\"Collect\") as bar:\n",
    "        for movieCd in batch:\n",
    "            try:\n",
    "                info = fetch_movie_info(movieCd)\n",
    "            except Exception as e:\n",
    "                print(\"info ì‹¤íŒ¨:\", movieCd, e); bar.update(1); continue\n",
    "\n",
    "            # í•œêµ­ êµ­ê°€/ê°œë´‰ì¼ ê¸°ë³¸ ê²€ì¦ (ì•ˆì „ë§)\n",
    "            nations = [n.get(\"nationNm\") for n in (info.get(\"nations\") or [])]\n",
    "            if not any(str(n).strip() in {\"í•œêµ­\",\"ëŒ€í•œë¯¼êµ­\",\"Korea\",\"South Korea\",\"Republic of Korea\"} for n in nations):\n",
    "                bar.update(1); append_done_id(movieCd); continue\n",
    "\n",
    "            try:\n",
    "                s_final, a_final = intelligent_final_acc(movieCd, info.get(\"openDt\"), cache)\n",
    "            except Exception as e:\n",
    "                print(\"weekly ì‹¤íŒ¨:\", movieCd, e)\n",
    "                s_final, a_final = (pd.NA, pd.NA)\n",
    "\n",
    "            row = to_tmdb_row(info, s_final, a_final)\n",
    "            append_partial_row(row)\n",
    "            append_done_id(movieCd)\n",
    "            bar.update(1)\n",
    "\n",
    "    # ì›í•  ë•Œ ìµœì¢… CSVë¡œ ì¬ì •ë ¬/ë¨¸ì§€\n",
    "    cols = [\"movie_id\",\"title\",\"original_title\",\"original_language\",\"release_date\",\"runtime\",\"budget\",\n",
    "            \"revenue\",\"vote_average\",\"vote_count\",\"popularity\",\"genres\",\"production_companies\",\n",
    "            \"production_countries\",\"release_year\",\"release_month\",\"audience_total\"]\n",
    "\n",
    "    part = pd.read_csv(OUT_PARTIAL, dtype=str)\n",
    "    # íƒ€ì…/ì •ë ¬ ë³´ì •\n",
    "    part[\"release_year\"]  = pd.to_numeric(part[\"release_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    part[\"release_month\"] = pd.to_numeric(part[\"release_month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    part[\"runtime\"]       = pd.to_numeric(part[\"runtime\"], errors=\"coerce\")\n",
    "    part[\"revenue\"]       = pd.to_numeric(part[\"revenue\"], errors=\"coerce\")\n",
    "    part[\"audience_total\"]= pd.to_numeric(part[\"audience_total\"], errors=\"coerce\")\n",
    "    part = part.drop_duplicates(subset=[\"movie_id\"]).sort_values([\"release_year\",\"release_month\",\"title\"])\n",
    "    part.reindex(columns=cols).to_csv(OUT_FINAL, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… ìµœì¢… ë³‘í•© ì €ì¥: {OUT_FINAL} (rows={len(part):,})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b7a1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ë²ˆ ë°°ì¹˜: 800í¸ / ë‚¨ì€ 2251í¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "movieInfo + merge (KR only):   0%|          | 1/800 [00:03<42:44,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip 20040756 KOBIS fault: ìœ íš¨í•˜ì§€ì•Šì€ í‚¤ê°’ì…ë‹ˆë‹¤. (code=320010)\n",
      "URL: https://www.kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieInfo.json?key=%2283eff9d2cad944234ee5924c9e498a61%22+%23+%EB%8F%84%EB%AF%BC+2&movieCd=20040756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "movieInfo + merge (KR only):   0%|          | 1/800 [00:06<1:24:34,  6.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mkobis_get\u001b[39m\u001b[34m(path, params, retry)\u001b[39m\n\u001b[32m     59\u001b[39m     fi = data[\u001b[33m\"\u001b[39m\u001b[33mfaultInfo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKOBIS fault: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi.get(\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (code=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi.get(\u001b[33m'\u001b[39m\u001b[33merrorCode\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mURL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m time.sleep(SLEEP)\n",
      "\u001b[31mRuntimeError\u001b[39m: KOBIS fault: ìœ íš¨í•˜ì§€ì•Šì€ í‚¤ê°’ì…ë‹ˆë‹¤. (code=320010)\nURL: https://www.kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieInfo.json?key=%2283eff9d2cad944234ee5924c9e498a61%22+%23+%EB%8F%84%EB%AF%BC+2&movieCd=20040706",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 228\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… ì €ì¥: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUT_FINAL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (rows=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(part)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 186\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cd \u001b[38;5;129;01min\u001b[39;00m tqdm(batch, desc=\u001b[33m\"\u001b[39m\u001b[33mmovieInfo + merge (KR only)\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         info = \u001b[43mfetch_movie_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m         \u001b[38;5;66;03m# í•œêµ­ ì œì‘ í•„í„° + ê°œë´‰ì¼(ê¸°ê°„ ë‚´ ì•ˆì „ë§)\u001b[39;00m\n\u001b[32m    188\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_korean_production(info):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 117\u001b[39m, in \u001b[36mfetch_movie_info\u001b[39m\u001b[34m(cd)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch_movie_info\u001b[39m(cd: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     js = \u001b[43mkobis_get\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/movie/searchMovieInfo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmovieCd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcd\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m js.get(\u001b[33m\"\u001b[39m\u001b[33mmovieInfoResult\u001b[39m\u001b[33m\"\u001b[39m,{}).get(\u001b[33m\"\u001b[39m\u001b[33mmovieInfo\u001b[39m\u001b[33m\"\u001b[39m,{}) \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mkobis_get\u001b[39m\u001b[34m(path, params, retry)\u001b[39m\n\u001b[32m     64\u001b[39m         last = e\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m i == retry-\u001b[32m1\u001b[39m: \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(last)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# kobis_weekly_to_tmdb_csv.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "2005-01-01 ~ 2025-12-31\n",
    "KOBIS(=KOFIC OpenAPI)ì—ì„œ 'ì£¼ê°„ ë°•ìŠ¤ì˜¤í”¼ìŠ¤ Top10ì— í•œ ë²ˆì´ë¼ë„ ë“±ì¥'í•œ ì˜í™”ë§Œ ì„ ë³„\n",
    "â†’ í•œêµ­ ì œì‘ë§Œ í•„í„° â†’ TMDB ìŠ¤íƒ€ì¼ ìŠ¤í‚¤ë§ˆ CSV ìƒì„±\n",
    "(revenue = êµ­ë‚´ ìµœì¢… ëˆ„ì ë§¤ì¶œ, audience_total = êµ­ë‚´ ìµœì¢… ëˆ„ì ê´€ê°)\n",
    "\n",
    "ì¶œë ¥ ì—´ ìˆœì„œ:\n",
    "movie_id,title,original_title,original_language,release_date,runtime,budget,\n",
    "revenue,vote_average,vote_count,popularity,genres,production_companies,\n",
    "production_countries,release_year,release_month,audience_total\n",
    "\"\"\"\n",
    "\n",
    "import os, time, json, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime, timedelta\n",
    "from urllib.parse import urlencode\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ========= ê¸°ê°„/ê²½ë¡œ ì„¤ì • =========\n",
    "START = date(2005, 1, 1)\n",
    "END   = date(2025,12,31)\n",
    "\n",
    "OUT_DIR       = \"./data_processed\"\n",
    "WEEKLY_PICKLE = f\"{OUT_DIR}/kobis_weekly_pool.pkl\"      # ì£¼ê°„ ìŠ¤ìº” ê²°ê³¼ ìºì‹œ\n",
    "OUT_PARTIAL   = f\"{OUT_DIR}/kobis_weekly_partial.csv\"   # ë©”íƒ€ ëˆ„ì (ì¬ì‹œì‘ìš©)\n",
    "OUT_FINAL     = f\"{OUT_DIR}/kobis_weekly_final.csv\"     # ìµœì¢… TMDBí˜•\n",
    "\n",
    "# í•˜ë£¨ì— ì²˜ë¦¬í•  movieInfo ê°œìˆ˜(ì¿¼í„° ë”°ë¼ ì¡°ì •)\n",
    "MOVIES_PER_RUN = 800\n",
    "\n",
    "# ìš”ì²­/ì¬ì‹œë„\n",
    "TIMEOUT = 20\n",
    "RETRY   = 3\n",
    "SLEEP   = 0.12\n",
    "\n",
    "# ========= ì¸ì¦ =========\n",
    "load_dotenv()\n",
    "KOBIS_KEY = os.getenv(\"KOFIC_API_KEY\") or os.getenv(\"KOBIS_KEY\")\n",
    "BASE = \"https://www.kobis.or.kr/kobisopenapi/webservice/rest\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ========= ê³µí†µ HTTP =========\n",
    "def kobis_get(path, params, retry=RETRY):\n",
    "    q = {\"key\": KOBIS_KEY, **params}\n",
    "    url = f\"{BASE}{path}.json?{urlencode(q)}\"\n",
    "    last = None\n",
    "    for i in range(retry):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=TIMEOUT)\n",
    "            if r.status_code in (429,500,502,503,504):\n",
    "                time.sleep(min(2**i,8)); continue\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if data.get(\"faultInfo\"):\n",
    "                fi = data[\"faultInfo\"]\n",
    "                raise RuntimeError(f\"KOBIS fault: {fi.get('message')} (code={fi.get('errorCode')})\\nURL: {url}\")\n",
    "            time.sleep(SLEEP)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            if i == retry-1: raise\n",
    "            time.sleep(min(2**i,8))\n",
    "    raise RuntimeError(last)\n",
    "\n",
    "# ========= ìœ í‹¸ =========\n",
    "def sundays(start: date, end: date):\n",
    "    # start ê¸°ì¤€ ê·¸ ì£¼ ì¼ìš”ì¼(weekGb=0 ì‚¬ìš©)\n",
    "    s = start + timedelta(days=(6 - start.weekday()))\n",
    "    while s <= end:\n",
    "        yield s\n",
    "        s += timedelta(days=7)\n",
    "\n",
    "def to_iso_from_yyyymmdd(s):\n",
    "    if not s: return pd.NA\n",
    "    s = str(s)\n",
    "    return f\"{s[:4]}-{s[4:6]}-{s[6:]}\" if len(s) >= 8 else pd.NA\n",
    "\n",
    "def json_list_str(xs):\n",
    "    if xs is None: return \"[]\"\n",
    "    if isinstance(xs, list): return json.dumps(xs, ensure_ascii=False)\n",
    "    return json.dumps([str(xs)], ensure_ascii=False)\n",
    "\n",
    "# ========= 1) ì£¼ê°„ Top10 ìŠ¤ìº”: ë“±ì¥ ì˜í™” + ìµœì¢… ëˆ„ì  =========\n",
    "def weekly_scan():\n",
    "    \"\"\"\n",
    "    ì£¼ê°„ ë°•ìŠ¤ì˜¤í”¼ìŠ¤(Top10) ì „ì²´ ì£¼ì°¨ ìŠ¤ìº” â†’ movieCdë³„ ìµœëŒ“ê°’ ëˆ„ì ë§¤ì¶œ/ê´€ê° ë° ê¸°ë³¸ ì •ë³´ ëª¨ìŒ\n",
    "    ë°˜í™˜: dict[movieCd] = {max_sales, max_audi, movieNm, openDt, weeks}\n",
    "    \"\"\"\n",
    "    pool = {}  # movieCd -> dict\n",
    "    for s in tqdm(list(sundays(START, END)), desc=\"Weekly scan (Top10)\"):\n",
    "        js = kobis_get(\"/boxoffice/searchWeeklyBoxOfficeList\",\n",
    "                       {\"targetDt\": s.strftime(\"%Y%m%d\"), \"weekGb\": \"0\"})\n",
    "        items = js.get(\"boxOfficeResult\",{}).get(\"weeklyBoxOfficeList\",[]) or []\n",
    "        for it in items:\n",
    "            cd  = it.get(\"movieCd\")\n",
    "            if not cd: continue\n",
    "            nm  = it.get(\"movieNm\")\n",
    "            odt = it.get(\"openDt\")  # yyyymmdd\n",
    "            salesAcc = pd.to_numeric(it.get(\"salesAcc\"), errors=\"coerce\") or 0\n",
    "            audiAcc  = pd.to_numeric(it.get(\"audiAcc\"),  errors=\"coerce\") or 0\n",
    "            rec = pool.get(cd, {\"max_sales\":0, \"max_audi\":0, \"movieNm\":nm, \"openDt\":odt, \"weeks\":0})\n",
    "            rec[\"max_sales\"] = max(rec[\"max_sales\"], salesAcc)\n",
    "            rec[\"max_audi\"]  = max(rec[\"max_audi\"],  audiAcc)\n",
    "            rec[\"weeks\"]     = rec[\"weeks\"] + 1\n",
    "            if not rec.get(\"movieNm\"):  rec[\"movieNm\"] = nm\n",
    "            if not rec.get(\"openDt\"):   rec[\"openDt\"]  = odt\n",
    "            pool[cd] = rec\n",
    "    pd.to_pickle(pool, WEEKLY_PICKLE)\n",
    "    return pool\n",
    "\n",
    "# ========= 2) movieInfo ë©”íƒ€(í•œêµ­ ì œì‘ í•„í„°) + TMDB ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜ =========\n",
    "def fetch_movie_info(cd: str):\n",
    "    js = kobis_get(\"/movie/searchMovieInfo\", {\"movieCd\": cd})\n",
    "    return js.get(\"movieInfoResult\",{}).get(\"movieInfo\",{}) or {}\n",
    "\n",
    "def is_korean_production(info) -> bool:\n",
    "    nations = [n.get(\"nationNm\") for n in (info.get(\"nations\") or []) if n.get(\"nationNm\")]\n",
    "    return any(str(n).strip() in {\"í•œêµ­\",\"ëŒ€í•œë¯¼êµ­\",\"Korea\",\"South Korea\",\"Republic of Korea\"} for n in nations)\n",
    "\n",
    "def to_tmdb_row(cd, pool_rec, info):\n",
    "    movieNm   = info.get(\"movieNm\") or pool_rec.get(\"movieNm\")\n",
    "    movieNmEn = info.get(\"movieNmEn\") or movieNm\n",
    "    openDt    = info.get(\"openDt\") or pool_rec.get(\"openDt\")\n",
    "    iso       = to_iso_from_yyyymmdd(openDt)\n",
    "    dt        = pd.to_datetime(iso, errors=\"coerce\") if pd.notna(iso) else pd.NaT\n",
    "\n",
    "    showTm    = pd.to_numeric(info.get(\"showTm\"), errors=\"coerce\")\n",
    "    genres    = [g.get(\"genreNm\")   for g in (info.get(\"genres\")   or []) if g.get(\"genreNm\")]\n",
    "    companies = [c.get(\"companyNm\") for c in (info.get(\"companys\") or []) if c.get(\"companyNm\")]\n",
    "\n",
    "    return {\n",
    "        \"movie_id\": cd,\n",
    "        \"title\": movieNm,\n",
    "        \"original_title\": movieNmEn,\n",
    "        \"original_language\": \"ko\",\n",
    "        \"release_date\": iso,\n",
    "        \"runtime\": showTm,\n",
    "        \"budget\": pd.NA,\n",
    "        \"revenue\": float(pool_rec[\"max_sales\"]),       # êµ­ë‚´ ìµœì¢… ëˆ„ì ë§¤ì¶œ(ì›)\n",
    "        \"vote_average\": pd.NA,\n",
    "        \"vote_count\": pd.NA,\n",
    "        \"popularity\": pd.NA,\n",
    "        \"genres\": json_list_str(genres),\n",
    "        \"production_companies\": json_list_str(companies),\n",
    "        \"production_countries\": json_list_str([\"KR\"]),\n",
    "        \"release_year\": (dt.year  if pd.notna(dt) else pd.NA),\n",
    "        \"release_month\": (dt.month if pd.notna(dt) else pd.NA),\n",
    "        \"audience_total\": float(pool_rec[\"max_audi\"]), # êµ­ë‚´ ìµœì¢… ëˆ„ì ê´€ê°\n",
    "    }\n",
    "\n",
    "# ========= 3) ì‹¤í–‰(ì¬ì‹œì‘ ê°€ëŠ¥) =========\n",
    "def main():\n",
    "    if not KOBIS_KEY:\n",
    "        raise SystemExit(\"âŒ .envì— KOFIC_API_KEY(=KOBIS_KEY)ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 1) ì£¼ê°„ ìŠ¤ìº”(ìºì‹œ í™œìš©)\n",
    "    if os.path.exists(WEEKLY_PICKLE):\n",
    "        pool = pd.read_pickle(WEEKLY_PICKLE)\n",
    "    else:\n",
    "        pool = weekly_scan()\n",
    "\n",
    "    # ì£¼ê°„ì— í•œ ë²ˆì´ë¼ë„ ì¡íŒ ì˜í™”ë§Œ(=ëˆ„ì ë§¤ì¶œ ì¶”ì  ê°€ëŠ¥)\n",
    "    candidates = [cd for cd, rec in pool.items() if rec.get(\"max_sales\",0) > 0]\n",
    "\n",
    "    # 2) ì´ë¯¸ ìˆ˜ì§‘í•œ partial ì½ê¸°(ì¬ì‹œì‘)\n",
    "    done = set()\n",
    "    if os.path.exists(OUT_PARTIAL):\n",
    "        prev = pd.read_csv(OUT_PARTIAL, dtype=str)\n",
    "        if \"movie_id\" in prev.columns:\n",
    "            done = set(prev[\"movie_id\"].astype(str).tolist())\n",
    "\n",
    "    todo = [cd for cd in candidates if cd not in done]\n",
    "    if not todo:\n",
    "        print(\"âœ… ëª¨ë‘ ì²˜ë¦¬ë¨. ìµœì¢… íŒŒì¼ë§Œ ì •ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        batch = todo[:MOVIES_PER_RUN]\n",
    "        print(f\"ì´ë²ˆ ë°°ì¹˜: {len(batch)}í¸ / ë‚¨ì€ {len(todo)-len(batch)}í¸\")\n",
    "\n",
    "        rows = []\n",
    "        for cd in tqdm(batch, desc=\"movieInfo + merge (KR only)\"):\n",
    "            try:\n",
    "                info = fetch_movie_info(cd)\n",
    "                # í•œêµ­ ì œì‘ í•„í„° + ê°œë´‰ì¼(ê¸°ê°„ ë‚´ ì•ˆì „ë§)\n",
    "                if not is_korean_production(info):\n",
    "                    continue\n",
    "                odt = info.get(\"openDt\") or pool[cd].get(\"openDt\")\n",
    "                if not odt or len(str(odt)) != 8:\n",
    "                    continue\n",
    "                # ê¸°ê°„ ì•ˆì „ë§ (ì—´ë¦° ë‚ ì§œ ê¸°ì¤€)\n",
    "                y, m, d = int(odt[:4]), int(odt[4:6]), int(odt[6:8])\n",
    "                opened = date(y,m,d)\n",
    "                if opened < START or opened > END:\n",
    "                    continue\n",
    "\n",
    "                row = to_tmdb_row(cd, pool[cd], info)\n",
    "                rows.append(row)\n",
    "            except Exception as e:\n",
    "                print(\"skip\", cd, e)\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows)\n",
    "            header = not os.path.exists(OUT_PARTIAL)\n",
    "            df.to_csv(OUT_PARTIAL, index=False, mode=(\"w\" if header else \"a\"),\n",
    "                      header=header, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 3) ìµœì¢… ì •ë¦¬/ì €ì¥(TMDB ìŠ¤í‚¤ë§ˆ)\n",
    "    cols = [\"movie_id\",\"title\",\"original_title\",\"original_language\",\"release_date\",\"runtime\",\"budget\",\n",
    "            \"revenue\",\"vote_average\",\"vote_count\",\"popularity\",\"genres\",\"production_companies\",\n",
    "            \"production_countries\",\"release_year\",\"release_month\",\"audience_total\"]\n",
    "\n",
    "    part = pd.read_csv(OUT_PARTIAL, dtype=str) if os.path.exists(OUT_PARTIAL) else pd.DataFrame(columns=cols)\n",
    "    if not part.empty:\n",
    "        part[\"release_year\"]   = pd.to_numeric(part[\"release_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        part[\"release_month\"]  = pd.to_numeric(part[\"release_month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        part[\"runtime\"]        = pd.to_numeric(part[\"runtime\"], errors=\"coerce\")\n",
    "        part[\"revenue\"]        = pd.to_numeric(part[\"revenue\"], errors=\"coerce\")\n",
    "        part[\"audience_total\"] = pd.to_numeric(part[\"audience_total\"], errors=\"coerce\")\n",
    "        part = part.drop_duplicates(subset=[\"movie_id\"]).sort_values([\"release_year\",\"release_month\",\"title\"])\n",
    "\n",
    "    part.reindex(columns=cols).to_csv(OUT_FINAL, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… ì €ì¥: {OUT_FINAL} (rows={len(part):,})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
